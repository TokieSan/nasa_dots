Earthquakes have long been recognized as resulting from a stick–slip frictional instability. The development of a full constitutive law for rock friction now shows that the gamut of earthquake phenomena—seismogenesis and seismic coupling, pre- and post-seismic phenomena, and the insensitivity of earthquakes to stress transients—all appear as manifestations of the richness of this friction law.

Main
The traditional view of tectonics is that the lithosphere comprises a strong brittle layer overlying a weak ductile layer, which gives rise to two forms of deformation: brittle fracture, accompanied by earthquakes, in the upper layer, and aseismic ductile flow in the layer beneath. Although this view is not incorrect, it is imprecise, and in ways that can lead to serious misunderstandings. The term ductility, for example, can apply equally to two common rock deformation mechanisms: crystal plasticity, which occurs in rock above a critical temperature, and cataclastic flow, a type of granular deformation which can occur in poorly consolidated sediments. Although both exhibit ductility, these two deformation mechanisms have very different rheologies. Earthquakes, in turn, are associated with strength and brittleness—associations that are likewise sufficiently imprecise that, if taken much beyond the generality implied in the opening sentence, they can lead to serious misinterpretations about earthquake mechanics.

Lately, a newer, much more precise and predictive model for the earthquake mechanism has emerged, which has its roots in the observation that tectonic earthquakes seldom if ever occur by the sudden appearance and propagation of a new shear crack (or ‘fault’). Instead, they occur by sudden slippage along a pre-existing fault or plate interface. They are therefore a frictional, rather than fracture, phenomenon, with brittle fracture playing a secondary role in the lengthening of faults1 and frictional wear2. This distinction was noted by several early workers3, but it was not until 1966 that Brace and Byerlee4 pointed out that earthquakes must be the result of a stick–slip frictional instability. Thus, the earthquake is the ‘slip’, and the ‘stick’ is the interseismic period of elastic strain accumulation. Subsequently, a complete constitutive law for rock friction has been developed based on laboratory studies. A surprising result is that a great many other aspects of earthquake phenomena also now seem to result from the nature of the friction on faults. The properties traditionally thought to control these processes—strength, brittleness and ductility—are subsumed within the overarching concept of frictional stability regimes.

Constitutive law of rock friction
In the standard model of stick–slip friction it is assumed that sliding begins when the ratio of shear to normal stress on the surface reaches a value μs, the static friction coefficient. Once sliding initiates, frictional resistance falls to a lower dynamic friction coefficient, μd, and this weakening of sliding resistance may, depending on the stiffness of the system, result in a dynamic instability. Following the suggestion of Brace and Byerlee, a great deal of attention was focused on the physics of rock friction, from which it was found that most of the statements in the standard model had to be revised. First, it was found that μs depends on the history of the sliding surface. If the surfaces are in static contact under load for time t, then μs increases slowly as log t (ref. 5). Second, the dynamic friction, when measured in the steady-state sliding regime, depends6 on the sliding velocity, V. This dependence, which goes as log V, may be either positive or negative, depending on the rock type and certain other parameters such as temperature7. Last, if subjected to a sudden change in sliding velocity, friction is found to evolve to its new steady-state value over a characteristic slip distance L (refs 8, 9).

The ageing of μs and the velocity dependence of μd are related behaviours10 which result from creep of the surface contact and a consequent increase in real contact area with time of contact11,12. The critical slip distance L is interpreted as a memory distance over which the contact population changes9,13,14. All of the experimental results are well described by an empirical, heuristic model known as the rate- and state-variable constitutive law, outlined in Box 1. This form of friction does not seem to be very material dependent: it also applies to some metals8 and to paper, wood and some plastics15,16. The former distinction between μs and μd disappears in this model. The base friction μo has a value nearly independent of rock type and temperature7,17. It is modified by second-order effects involving a dependence on sliding velocity and a state variable θ, and it is these second-order effects that result in the interesting modes of behaviour discussed here. The base friction, which determines the frictional strength of the fault, does not concern us in this discussion. The fault strength is not involved in the seismogenic behaviour of the fault, which is solely determined by its frictional stability, not its strength. Fault strength does play a role in frictional heating of faults, which can produce several interesting effects10,18 that will not be discussed here.

Box 1: Rate- and state-variable friction law
There are several forms of rate/state-variable constitutive law that have been used to model laboratory observations of rock friction. The version currently in best agreement with experimental data20, known as the Dieterich–Ruina or ‘slowness’ law, is expressed as


where τ is shear stress and σ¯ is effective normal stress (applied normal stress minus pore pressure). In the bracketed friction term, V is slip velocity, V0 a reference velocity, μ0 the steady-state friction at V = V0, and a and b are material properties. L is the critical slip distance and the state variable, θ, evolves according to:


The significance of these various terms is illustrated in the diagram below, which shows schematically but faithfully the experimentally observed frictional response to a suddenly imposed e-fold increase and then decrease in sliding velocity.


On initial application of the rate increase there is an increase a in friction, known as the direct velocity effect. This is followed by an evolutionary effect involving a decrease in friction, of magnitude b.

The friction at steady state is:


from which equation (1)in the main text arises. There is a continuum of changing friction values, but if dynamic friction, μd, is defined as steady-state friction at velocity V, then dμd/d(lnV) = a − b. Similarly, if static friction μs is defined as the starting friction following a period of time t in stationary contact, then for long t, dμs/d(lnt) = b. The name ‘slowness law’ arises because at steady state, the state variable is proportional to slowness, θss = l/V. The critical slip distance L is often interpreted as the sliding distance required to renew the contact population. In this view θss represents an average contact lifetime.

Show morefrom this box
Friction stability regimes and seismogenesis
Frictional stability depends on two friction parameters, L and the combined parameter (a − b), defined as the velocity dependence of steady-state friction (a and b are defined in Box 1):


The frictional stability regimes are described in Box 2. If (a − b) ⩾ 0, the material is said to be velocity strengthening, and will always be stable. In the velocity-weakening field, (a − b) < 0, there is a Hopf bifurcation between an unstable regime and a conditionally stable one. Considering a simple spring–slider model with fixed stiffness k, the bifurcation occurs at a critical value of effective normal stress, σ¯c, given by:


If σ¯ > σ¯c, sliding is unstable under quasistatic loading. In the conditionally stable regime, σ¯ <xs σ¯c, sliding is stable under quasistatic loading but can become unstable under dynamic loading if subjected to a velocity jump exceeding ΔV, as shown in Box 2. In a narrow region at the bifurcation, sliding occurs by a self-sustaining oscillatory motion6,15,19 (shaded region, in the second diagram in Box 2). Although the friction law described in Box 1can be written in several ways which differ in detail20, those details do not influence the above definitions of the stability states, which control the seismic behaviour of faults discussed here.

The three stability regimes have the following consequences for earthquakes. Earthquakes can nucleate only in those regions of a fault that lie within the unstable regime. They may propagate indefinitely into conditionally stable regions, provided that their dynamic stresses continue to produce a large enough velocity jump. If earthquakes propagate into a stable region, on the other hand, a negative stress drop will occur, resulting in a large energy sink that will rapidly stop the propagation of the earthquake.

The primary parameter that determines stability, (a − b), is a material property (see Box 1). The main systematics of this parameter that concern us are summarized in Fig. 1. Figure 1A shows the dependence of (a − b) on temperature for granite7,21. It is negative at low temperatures and becomes positive for temperatures above about 300 °C. This transition temperature corresponds to the onset of crystal plasticity of quartz, the most ductile of the major minerals in granite22. It may be a general statement that for low-porosity crystalline rocks a transition from negative to positive (a − b) corresponds to a change from elastic-brittle deformation to crystal plasticity in the micro-mechanics of friction. As another example, halite (rock salt), a much more ductile mineral, undergoes the same two corresponding transitions at 25 °C and a pressure of about 70 MPa (ref. 23). These observations indicate that for faults in granite, the representative rock of the continental crust, we should not expect earthquakes to occur below a depth at which the temperature is 300 °C, and faults in salt should be aseismic under almost all conditions.

Figure 1: Systematics of the friction parameter (a − b).
figure1
A, Dependence of (a − b) on temperature for granite (from refs 7, 21). B, Dependence of (a − b) on pressure for granulated granite (ref. 24). This effect, due to lithification, should be augmented with temperature.

Full size image
Faults are not simply frictional contacts of bare rock surfaces: they are usually lined with wear detritus, called cataclasite or fault gouge. The shearing of such granular material involves an additional hardening mechanism (involving dilatancy), which tends to make (a − b) more positive24. For such materials, (a − b) is positive when the material is poorly consolidated, but decreases at elevated pressure and temperature as the material becomes lithified (Fig. 1B). Therefore faults may also have a stable region near the surface, owing to the presence of such loosely consolidated material25.

These considerations allow the construction of synoptic models for the two primary sites of tectonic earthquakes, crustal faults and subduction zone interfaces, as shown in Fig. 2. In the centre of this figure is drawn the expected variation of the friction stability parameter ζ = (a − b)σ¯. This is positive at shallow depths because of the presence of unconsolidated granular material and at large depths because of the onset of plasticity at a critical temperature—hence, regions above and below these stability transitions are stable (shown blue). The regions in which the stability parameter exceeds the threshold defined in equation (2)are unstable, indicated by red, and yellow indicates the regions of conditional stability. Thus, the red regions define the seismogenic zone, the depth range over which earthquakes may nucleate, as indicated by their hypocentral depths, an example of which is given on the right of Fig. 2.

Figure 2: A synoptic model for stability as a function of depth for crustal faults and subduction zones.
figure2
The central panel and the crustal fault model are taken from ref. 22; the subduction zone model (left) is from refs 27, 28; the histogram of the depth distribution of earthquakes (right) is for a section of the San Andreas fault near Parkfield, California (data from ref. 25).

Full size image
For crustal faults, the upper transition depth is typically observed to be at 3–4 km, but may be absent at faults on which there has been little slip and hence little or no gouge developed25. The lower transition occurs at 15–20 km, corresponding to the onset of plasticity of quartz at about 300 °C. The depth at which this occurs depends on the local thermal gradient26. For subduction zones the upper transition occurs at the base of the accretionary prism of scraped-off oceanic sediments, where it encounters a ‘backstop’ of competent rock27. Because the thickness of the sedimentary wedge is quite variable, so is the depth of this transition—it may be as deep as 10 km. The lower transition occurs at depths as great as 45 km at subduction zones. This greater depth is a result of lower thermal gradients, owing to the subduction of the cold oceanic plate, although this may vary widely because of variations in the age of the subducting plate, which strongly affects the thermal regime28. The transition is also deeper because the basalt of the oceanic plate contains no quartz—the most ductile mineral in basalt is feldspar, which becomes plastic at about 450 °C (ref. 22). Because the seismogenic zone is much wider than for crustal faults—up to 150 km—and because they tend to be more continuous along strike, subduction zones produce by far the largest earthquakes in the world.

If a large earthquake occurs on a crustal fault, it will often have enough energy to propagate through the narrow shallow stable region and breach the surface. It may also often propagate a short distance into the ductile stable region at depth, for which there is geological evidence29,30. However, for subduction zones with a wide accretionary prism, large earthquakes will often not breach the surface. Whether they do or not is thought to be important in determining how efficient they are in generating tsunamis31.

Box 2: Stability regimes
Consider a simple spring-slider model with spring stiffness k, as shown in the diagram below, in which the slider obeys the rate/state-variable friction law.


The stability of this system depends entirely on σ¯, τ, k, the friction parameters (a − b) and L, and is independent of base friction μ0. The following are the conditions defining the stability regimes.

(a − b) > 0. This is velocity-strengthening behaviour, which is intrinsically stable. No earthquake can nucleate in this field, and any earthquake propagating into this field will produce there a negative stress drop, which will rapidly terminate propagation.

(a − b) <0. The stability diagram for the system exhibiting velocity weakening is shown in the diagram below.

This diagram shows the velocity jump, ΔV, necessary to destabilize the system as a function of the applied normal stress σ¯. If σ¯⩾ σ¯c, as defined by equation (2)in the main text, the system is unstable with respect to a vanishing velocity perturbation ΔV—that is, to quasistatic loading. This is the unstable field. If the effective normal stress is less than the critical value, it requires a finite velocity ‘kick’ to become unstable. Thus, in this conditionally stable field, the system is stable under quasistatic loading but may become unstable under sufficiently strong dynamic loading. Earthquakes may nucleate only in the unstable field, but may propagate into the conditionally stable field. At the border of the stability transition there is a narrow region in which self-sustaining oscillatory motion occurs, as indicated by the shaded region.

Show morefrom this box
Seismic coupling and seismic styles
The linear measure of earthquake size is seismic moment, M0 = GuA, where u is the mean slip in the earthquake, A the rupture area and G the shear modulus. The moment release rate of a fault or plate boundary is thus Ṁ0 = GvA where v is the long-term slip velocity and A is now the total fault area. We define the seismic coupling coefficient χ as the ratio of the moment release rate determined from summing earthquakes to the total rate obtained by determining v from a plate-tectonic model or geological data. The parameter χ is a good measure of the overall stability state of a fault. If the fault is entirely in the unstable field, χ = 1, and if entirely in the stable field χ = 0; otherwise, χ will be somewhere in between.

For most crustal faults, χ is indistinguishable from 1; that is, all of the fault slip occurs during earthquakes and these faults are said to be fully seismically coupled. An important exception is the so-called ‘creeping’ section of the San Andreas fault, a 170-km-long stretch in central California where the fault slips aseismically. Much of this aseismic slip occurs as ‘creep episodes' (Fig. 3), which appear to be the same as the oscillatory behaviour observed at the stability boundary—prima facie evidence that this part of the fault is in the conditionally stable regime close to the bifurcation of equation (2). It is sufficiently far from the stability boundary, though, to prevent earthquakes on neighbouring sections of the fault from propagating very far into this region. The most likely mechanism for the anomalous behaviour of this section of the fault is the presence there of unusually high pore pressures in the fault zone32. I note that the effective normal stress is σ¯ = (σ − p), where σ is the applied normal stress and p the pore pressure. If p approaches σ, the stability parameter ζ may be reduced so that the entire depth range of the fault normally in the unstable (red) field in Fig. 2 is shifted to the yellow field.

Figure 3: Oscillatory motion (creep episodes) of the creeping section of the San Andreas fault in central California (from ref. 10).
figure3
The straight line is for reference.

Full size image
Although such seismic decoupling seems to be rare for crustal faults, it is not rare for subduction zones, which vary from being fully coupled to almost entirely decoupled33. The difference seems to be due to the stress state. Stress measurements in deep boreholes34 in continents typically show that deviatoric stresses increase with depth so that at all depths the stresses are just below that necessary to cause sliding on a favourably oriented fault with a friction coefficient consistent with laboratory values (about 0.6). The pore pressures observed in deep boreholes usually increase with the hydrostatic gradient, and the vertical stress usually increases with the weight of the overlying rock. The most-studied fault, the San Andreas of California, seems to be exceptional, in that it seems to be sliding under very low shear stresses35. This can be consistent with the friction law only if the pore pressure within the fault is near the lithostatic load (weight of overburden), which is very problematical36. The important point is that crustal faults are subjected to remotely applied loads, and the effective normal stress on them is mainly determined by the lithostatic load minus the pore pressure, which is in the more usual case the hydrostatic head. For subduction zones, on the other hand, the forces that drive the plates are local to the subduction zone and may vary widely, which results in great variation of the effective normal stress supported by the plate interface. An analysis of the reduction of normal force (relative to a standard state) applied across subduction interfaces37, calculated from the plate-tectonic driving forces, is shown in Fig. 4 for most of the world's subduction zones. The seismic coupling coefficient χ, determined from seismicity data, decreases from high to low values at a critical value corresponding to σ¯c, which was determined independently of the data shown in the figure. Owing to the shortness of the seismic record, these values of χ are not very well determined38, but they are good enough to allow one to distinguish the coupled from the decoupled zones. Thus coupled and decoupled subduction zones are on either side of the stability transition boundary. On a local scale, irregularities caused, for example, by the subduction of seamounts can produce local increases in normal stress with the result that otherwise decoupled subduction zones may become locally coupled39.

Figure 4: The observed seismic coupling coefficient χ versus the calculated reduction in normal force from a standard state for most of.
figure4
the Earth's subduction zones (after ref. 37). The transition point, σ¯c, was independently estimated from the Izu-Bonin/Mariana arc.

Full size image
The three stability states result in three distinctive seismic styles. Regions with the stable field, such as the outer parts of accretionary prisms and faults in salt, are totally aseismic27,40. Faults in the unstable field are characterized by infrequent large earthquakes separated by long interseismic periods of quiescence. On the other hand, faults in the conditionally stable regime, such as the creeping section of the San Andreas and the decoupled subduction zones, are characterized by high steady rates of small-event activity and no large events (‘large’ events are earthquakes that rupture the entire seismogenic thickness). These small events together contribute very little to the total moment release, which is primarily aseismic39,41. Small events are found to occur repeatedly with a high repetition rate at the same spots42. These spots may mark small geometric irregularities43 where the normal stress is higher, causing a transition to the unstable field.

Stages in the seismic cycle
As noted above, seismically coupled faults are typified by infrequent large events, separated by long quiescent interseismic periods in which the stresses relaxed by the preceding earthquake are restored. A frictional model of the seismic cycle of a strike–slip fault44,45, purposely reminiscent of the San Andreas fault, is shown in Fig. 5. In this two-dimensional model, the fault is driven remotely at a constant velocity; the figure shows the slip on the fault as a function of depth at different times during the seismic cycle. The only assumption in the model is that it obeys the friction law of Box 1with the (a − b) parameter varying as in Fig. 1A and σ¯ increasing with depth in a way consistent with the borehole data summarized above. The depth of the transition from unstable to stable regimes is at 11 km, in accordance with the geothermal gradient typical of the San Andreas fault.

Figure 5: Slip as a function of depth over the seismic cycle of a strike–slip fault, using a frictional model containing a transition.
figure5
from unstable to stable friction at 11 km depth (after ref. 44).

Full size image
During the interseismic period (shown blue in Fig. 5), the fault is loaded by steady slip on the deep, stable portion of the fault. Just before the earthquake a pre-seismic phase, known as nucleation, occurs (orange); in this phase, slip accelerates until the instability results in the coseismic motions (red). These penetrate below the stability boundary, reloading that region, which relaxes in a post-seismic phase of accelerated deep slip (green), at a rate that decays exponentially with time within a few years to a decade following the mainshock. Geodetic data strongly support the main features of this model46,47,48: the interseismic strain accumulation resulting from deep slip below a locking depth, above which the coseismic slip occurs, and a postseismic relaxation phase with decelerating deep slip49. The pre-seismic nucleation phase is sometimes associated with the occurrence of foreshocks50, and may also be responsible for certain other precursory phenomena that have been occasionally observed10.

A shallow relaxation phenomenon called afterslip is often observed, in which a fault slips aseismically at the surface in proportion to the logarithm of the time elapsed since an earthquake just below. Afterslip is usually observed where a thick layer of poorly consolidated sediments overlies the fault, which partially or totally impedes the earthquake from breaching the surface. Afterslip can be described by a model similar to that illustrated in Fig. 5 but with a thick stable layer at the top51; an example is shown in Fig. 6. This phenomenon has also been observed in partially coupled subduction zones, where an earthquake in an unstable patch drives afterslip in adjacent conditionally stable or stable regions52. The other typical postseismic phenomena, aftershock sequences, which obey a well defined hyperbolic decay law known as the Omori law, have also been shown to be a prediction of the rate- and state-variable friction law53. This part of the theory has also been successfully tested with observations54.

Figure 6
figure6
Afterslip observed at the surface following two large strike-slip earthquakes compared with the results of a numerical model of slip in a stable layer overlying an unstable region which slipped coseismically (from ref. 51).

Full size image
When the instability condition for a one-dimensional spring slider, equation (2), is generalized for the two- or three-dimensional case of a slipping patch of size L, the stiffness, k, scales inversely with L according to k = ηG/L, where G is the shear modulus and η is a geometrical constant of the order of unity. This implies that the instability occurs when the slipping patch reaches a critical size Lc, the nucleation length, given by:


Modelling55 and laboratory observations6,56 of this nucleation process indicate that stable sliding initiates at a point and then spreads out with an accelerating sliding velocity until the instability arises at Lc. Whether or not such nucleation occurs on natural faults, and whether it is large enough to be detected, is central to the problem of short-term earthquake prediction. However, the physical significance and scaling of the key parameter L is not known. It is very small (∼10 μm) in the laboratory. Various attempts to model L, assuming that it is a property of the surface contact topography57 or gouge zone thickness58, suggest that it may be much larger at the fault scale. If Lc is a constant for natural faults, it also represents a minimum earthquake dimension. In that case Lc <10 m, the rupture size of the smallest observed earthquakes59. On the other hand, observations of the dimensions of foreshock zones and of a precursory seismic phase both indicate that nucleation length may be of the order of kilometres and scale with the size of the ensuing earthquake60,61.

Earthquake insensitivity to transients
There is one last property of this friction law which clears up some long-known mysteries about earthquakes. The direct friction effect (Box 1) and the finite size and duration of nucleation prohibit earthquakes from being triggered by high-frequency stress oscillations62,75. Hence, as has been repeatedly verified over the past 75 years, earthquakes are not triggered by Earth tides63. They are also not triggered (except in magmatic systems64) by the seismic waves from other earthquakes65, even though the smaller residual static stresses from earthquakes may trigger earthquakes following some time delay66.

Outstanding problems in earthquake mechanics
There are, of course, many details yet to be worked out about the friction law, its parameters, and their scaling properties and applications to natural seismic phenomena. The scaling of L and its effect on nucleation is but one of these. But, lest the above discussion give the impression that most of what is worth knowing about earthquake mechanics is now well understood, I will describe several important problems that are currently at issue.

One important question is: what gives rise to the complexity of earthquakes? Earthquake populations obey a very well defined power-law size distribution, known as the Gutenberg–Richter law—such power laws being the hallmarks of systems exhibiting ‘self-organized criticality’ (ref. 76). The internal dynamics of earthquakes also exhibit complexity, with very broad-band velocity and acceleration spectra, while at the same time obeying well defined self-similar scaling laws in terms of the static parameters10. Is this complexity a result of the heterogeneity of faults, which have quasi-fractal scaling of surface topography67, or of the nonlinearity of the friction laws, or both?

Dynamic models of arrays of spring-coupled block sliders68,69,70 obeying simple versions of these friction laws have been successful in reproducing Gutenberg–Richter statistics and many other aspects of observed earthquake complexity. These models assume no built-in heterogeneity, hence these results imply that this complexity may arise solely from the nonlinearity of the friction. On the other hand, continuum models show that complexity does not arise easily from the friction alone45,71, unless extreme values for the friction parameters are assumed72. But these studies are far from exploring all regimes of friction parameter space. Furthermore, as remarked on below, the friction laws are still quite simple: there may be other aspects not yet uncovered in laboratory experiments.

There is a newly discovered class of earthquakes that are not expected from the friction laws as currently formulated: these are the ‘slow’ earthquakes, which are characterized by moment release rates much lower than those seen in other earthquakes73. A slow earthquake occurring at a subduction zone may generate a much larger tsunami than expected from its moment as measured in the usual frequency band74. One might suppose that some additional dissipative term, not yet recognized in the laboratory, may be present in order to explain this kind of earthquake.

Although there are many interesting phenomena yet to be explored, the success of the rate- and state-variable friction laws, simple as they are, in explaining a wide range of earthquake phenomena gives confidence that they will provide the basis for many exciting future discoveries as well.

Human-induced earthquakes have become an important topic of political and scientific discussion, owing to the concern that these events may be responsible for widespread damage and an overall increase in seismicity. It has long been known that impoundment of reservoirs, surface and underground mining, withdrawal of fluids and gas from the subsurface, and injection of fluids into underground formations are capable of inducing earthquakes. In particular, earthquakes caused by injection have become a focal point, as new drilling and well-completion technologies enable the extraction of oil and gas from previously unproductive formations.

Embedded Image

Earthquakes with magnitude (M) ≥ 3 in the U.S. midcontinent, 1967–2012. After decades of a steady earthquake rate (average of 21 events/year), activity increased starting in 2001 and peaked at 188 earthquakes in 2011. Human-induced earthquakes are suspected to be partially responsible for the increase.

Advances
Microearthquakes (that is, those with magnitudes below 2) are routinely produced as part of the hydraulic fracturing (or “fracking”) process used to stimulate the production of oil, but the process as currently practiced appears to pose a low risk of inducing destructive earthquakes. More than 100,000 wells have been subjected to fracking in recent years, and the largest induced earthquake was magnitude 3.6, which is too small to pose a serious risk. Yet, wastewater disposal by injection into deep wells poses a higher risk, because this practice can induce larger earthquakes. For example, several of the largest earthquakes in the U.S. midcontinent in 2011 and 2012 may have been triggered by nearby disposal wells. The largest of these was a magnitude 5.6 event in central Oklahoma that destroyed 14 homes and injured two people. The mechanism responsible for inducing these events appears to be the well-understood process of weakening a preexisting fault by elevating the fluid pressure. However, only a small fraction of the more than 30,000 wastewater disposal wells appears to be problematic—typically those that dispose of very large volumes of water and/or communicate pressure perturbations directly into basement faults.

Outlook
Injection-induced earthquakes, such as those that struck in 2011, clearly contribute to the seismic hazard. Quantifying their contribution presents difficult challenges that will require new research into the physics of induced earthquakes and the potential for inducing large-magnitude events. The petroleum industry needs clear requirements for operation, regulators must have a solid scientific basis for those requirements, and the public needs assurance that the regulations are sufficient and are being followed. The current regulatory frameworks for wastewater disposal wells were designed to protect potable water sources from contamination and do not address seismic safety. One consequence is that both the quantity and timeliness of information on injection volumes and pressures reported to regulatory agencies are far from ideal for managing earthquake risk from injection activities. In addition, seismic monitoring capabilities in many of the areas in which wastewater injection activities have increased are not capable of detecting small earthquake activity that may presage larger seismic events.

Movers and Shakers
We tend to view earthquakes as unpredictable phenomena caused by naturally shifting stresses in Earth's crust. In reality, however, a range of human activity can also induce earthquakes. Ellsworth (p. 10.1126/science.1225942) reviews the current understanding of the causes and mechanics of earthquakes caused by human activity and the means to decrease their associated risk. Notable examples include injection of wastewater into deep formations and emerging technologies related to oil and gas recovery, including hydraulic fracturing. In addition to directly causing increased local seismic activity, activities such as deep fluid injection may have other ramifications related to earthquake occurrence. Van der Elst et al. (p. 164; see the news story by Kerr) demonstrate that in the midwestern United States, some areas with increased human-induced seismicity are also more prone to further earthquakes triggered by the seismic waves from large, remote earthquakes. Improved seismic monitoring and injection data near deep disposal sites will help to identify regions prone to remote triggering and, more broadly, suggest times when activities should, at least temporarily, be put on hold.

Abstract
Earthquakes in unusual locations have become an important topic of discussion in both North America and Europe, owing to the concern that industrial activity could cause damaging earthquakes. It has long been understood that earthquakes can be induced by impoundment of reservoirs, surface and underground mining, withdrawal of fluids and gas from the subsurface, and injection of fluids into underground formations. Injection-induced earthquakes have, in particular, become a focus of discussion as the application of hydraulic fracturing to tight shale formations is enabling the production of oil and gas from previously unproductive formations. Earthquakes can be induced as part of the process to stimulate the production from tight shale formations, or by disposal of wastewater associated with stimulation and production. Here, I review recent seismic activity that may be associated with industrial activity, with a focus on the disposal of wastewater by injection in deep wells; assess the scientific understanding of induced earthquakes; and discuss the key scientific challenges to be met for assessing this hazard.

The mechanism of the Aleutian islands earthquake of 1946 and the Sanriku earthquake of 1896 is studied on the basis of the data on seismic waves from 5 to 100 s and on tsunamis. These earthquakes generated, despite their relatively small earthquake magnitude, two of the largest and most widespread tsunamis in history. The data obtained at different periods are interpreted in terms of the effective moment, Me. The effective moment at a certain period is defined as a seismic moment of a virtual step function dislocation that explains the observation at this period. The effective moment of the tsunami earthquakes increases rapidly towards 0.5 to 1.0 × 1029 dyne · cm as the period increases while, for ordinary earthquakes, it is more or less constant. This dependence can be explained in terms of a source deformation having a time constant of about 100 s. The Mc versus ƒ (frequency) diagram provides a diagnostic method of estimating the tsunami potential of earthquakes. If the 
ƒ
 diagram for an earthquake has a steep upgrade towards low frequency implying an effective moment exceeding 1028 dyne · cm at zero frequency, the earthquake has a high tsunami potential. Since the determination of the effective moment at various periods can be made by a simple procedure, this method could be incorporated in the tsunami warning system. The abnormal slow deformation at the source of the tsunami earthquakes may be a manifestation of viscoelasticity of a weak zone beneath the inner margin of the trenches. The weak zone which is implied by large normal-fault earthquakes such as the 1933 Sanriku and the 1929 Aleutian islands earthquakes may be a result of frictional heating at the interface between the oceanic and the continental lithospheres.

The conventional magnitude scale M suffers saturation when the rupture dimension of the earthquake exceeds the wavelength of the seismic waves used for the magnitude determination (usually 5–50 km). This saturation leads to an inaccurate estimate of energy released in great earthquakes. To circumvent this problem the strain energy drop W (difference in strain energy before and after an earthquake) in great earthquakes is estimated from the seismic moment M0. If the stress drop Δσ is complete, W = W0 = (Δσ/2μ)M0 ∼ M0/(2×104), where μ is the rigidity; if it is partial, W0 gives the minimum estimate of the strain energy drop. Furthermore, if Orowan's condition, i.e., that frictional stress equal final stress, is met, W0 represents the seismic wave energy. A new magnitude scale Mw is defined in terms of W0 through the standard energy‐magnitude relation log W0 = 1.5Mw + 11.8. Mw is as large as 9.5 for the 1960 Chilean earthquake and connects smoothly to Ms (surface wave magnitude) for earthquakes with a rupture dimension of about 100 km or less. The Mw scale does not suffer saturation and is a more adequate magnitude scale for great earthquakes. The seismic energy release curve defined by W0 is entirely different from that previously estimated from Ms. During the 15‐year period from 1950 to 1965 the annual average of W0 is more than 1 order of magnitude larger than that during the periods from 1920 to 1950 and from 1965 to 1976. The temporal variation of the amplitude of the Chandler wobble correlates very well with the variation of W0, with a slight indication of the former preceding the latter. In contrast, the number N of moderate to large earthquakes increased very sharply as the Chandler wobble amplitude increased but decreased very sharply during the period from 1945 to 1965, when W0 was largest. One possible explanation for these correlations is that the increase in the wobble amplitude triggers worldwide seismic activity and accelerates plate motion which eventually leads to great decoupling earthquakes. This decoupling causes the decline of moderate to large earthquake activity. Changes in the rotation rate of the earth may be an important element in this mechanism.

Data from 40 historical world-wide earthquakes were studied to determine the characteristics, geologic environments, and hazards of landslides caused by seismic events. This sample of 40 events was supplemented with intensity data from several hundred United States earthquakes to study relations between landslide distribution and seismic parameters. Fourteen types of landslides were identified in the earthquakes studied. The most abundant of these were rock falls, disrupted soil slides, and rock slides. The greatest losses of human life were due to rock avalanches, rapid soil flows, and rock falls. Correlations between magnitude (M) and landslide distribution show that the maximum area likely to be affected by landslides in a seismic event increases from approximately 0 at M ≅ 4.0 to 500,000 km2 at M = 9.2.

Threshold magnitudes, minimum shaking intensities, and relations between M and distance from epicenter or fault rupture were used to define relative levels of shaking that trigger landslides in susceptible materials. Four types of internally disrupted landslides—rock falls, rock slides, soil falls, and disrupted soil slides—are initiated by the weakest shaking. More coherent, deeper-seated slides require stronger shaking; lateral spreads and flows require shaking that is stronger still; and the strongest shaking is probably required for very highly disrupted rock avalanches and soil avalanches.

Each type of earthquake-induced landslide occurs in a particular suite of geologic environments. These range from overhanging slopes of well-indurated rock to slopes of less than 1° underlain by soft, unconsolidated sediments. Materials most susceptible to earthquake-induced landslides include weakly cemented rocks, more-indurated rocks with prominent or pervasive discontinuities, residual and colluvial sand, volcanic soils containing sensitive clay, loess, cemented soils, granular alluvium, granular deltaic deposits, and granular man-made fill. Few earthquake-induced landslides reactivate older landslides; most are in materials that have not previously failed.

The accommodation of large strains in the upper crust is largely achieved by the accumulation of displacement on faults. Observation shows that as a fault accumulates displacement, it grows in size, i.e., its surface area and its length increase. Here we address the question: "For an increase in the amount of displacement on a fault, by how much would the length of the fault change?" It is argued by Cowie and Scholz [1992a] that the displacement on a fault is linearly related to the length of the fault. This simple result is expanded upon in this paper by assuming that a fault accumulates displacement by repeated earthquakes. Two different approaches are presented: The first approach considers the balance that must be achieved between the energy available for deformation and the work involved in creating new fault surface area as the fault grows. The available energy is provided by changes in strain energy when the fault slips. The second approach is to construct a geometrical model for fault growth using the scaling relationship between the slip during a single earthquake and the length of the rupture. The total displacement on a fault is the sum of the slips contributed by many earthquakes. The usefulness of these two approaches is that the growth of a fault over geologic time can be described by parameters that can be obtained from earthquake and fault data. The models presented here predict that (1) the maximum amount a fault can grow in a single earthquake that ruptures the entire fault is of the order of 1% of its previous length and (2) the work of faulting may account for 10% of the total energy available during an earthquake. The energy lost from the system is accounted for by work done against friction and seismic radiation. Consequences of fault growth for the segmentation and thus seismogenic potential of a fault over geologic time are discussed using predictions of the theory.

Considerable amounts of data indicate that the thickness of the gouge zone for brittle faults increases linearly with total slip. This implies that gouge is produced continuously and at a steady rate as faulting progresses. A simple model of wear which accounts for gouge formation predicts a constant thickness/slip ratio for a given rock type and normal stress. The model is compared with measurements of gouge production in friction-sliding experiments, and there is satisfactory agreement. Natural faults have higher wear rates than found in the experiments, probably because of their greater roughness. Estimates are also made of the fraction of the energy of faulting that goes into gouge production, and it is found to be 10-3 10-4 of the frictional work in both the experimental and natural cases. The model predicts that fault zones should thicken with depth in simple cases.

Friction experiments have been conducted on porous sandstone, quartzite, graywacke, and granite in the 20- to 850-bar normal stress range. Sliding on clean rough-ground surfaces is initially stable for this range. However, as powered rock debris accumulates on the slip surface, stick slip becomes the dominant mode of sliding. The coefficient of static friction of surfaces with gouge exhibits a highly time-dependent behavior. Static friction increases with the logarithm of the time that adjacent blocks remain in stationary contact. Over the entire range of normal stresses the static friction for 105-sec intervals between stick-slip events is greater than the static friction for 15-sec intervals by 6 to 10%. This behavior may be significant in understanding the mechanisms of earthquake foreshocks, aftershocks, and fault creep.

Detailed laboratory measurements have been made on the frictional characteristics of Westerly granite with ground surfaces and to normal stresses of 1 kb. These measurements show that for this type of surface there are three types of sliding: continuously stable, episodic stable, and stick-slip. All three of these modes have also been observed on the San Andreas fault in central California. In our laboratory experiments, there is a transition from the first to third mode at from 5 to 15 bars normal stress, above which stick-slip predominates. Stick-slip, however, is always preceded by a small amount of stable slip. If this occurs on a large scale on faults, it may be a promising premonitory effect for earthquake prediction. Loading rate is found to influence the frictional strength inversely, which may be an explanation for stick-slip. Stress drops were found to increase with shear stress, but not linearly, suggesting that radiation efficiency may increase with stress drop.

Stick-slip oscillations are normally analysed in terms of the kinetic friction-velocity and the static friction-time of stick characteristics of the rubbing surfaces. It is shown that, in addition, a critical distance, of the order of 10-3 cm, enters into the calculations, being the minimum resolving power of the friction process. Stick-slip oscillations must normally have an amplitude greater than the critical distance, and thus increased spring stiffness is often effective in eliminating stick-slip. Using the critical distance concept, it is possible to deduce a simple relationship between the static and kinetic coefficients of friction, and this is confirmed by experimental data.

Time-dependent increase of static friction is characteristic of rock friction undera variety of experimental circumstances. Data presented here show an analogous velocity-dependent effect. A theor of friction is proposed that establishes a common basis for static and sliding friction. Creep at points of contact causes increases in friction that are proportional to the logarithm of the time that the population of points of contact exist. For static friction that time is the time of stationary contact. For sliding friction the time of contact is determined by the critical displacement required to change the population of contacts and the slip velocity. An analysis of a one-dimensional spring and slider system shows that experimental observations establishing the transition from stable sliding to stick-slip to be a function of normal stress, stiffness and surface finish are a consequence of time-dependent friction.

Relocation of earthquakes recorded by the agency for meteorology, climatology and geophysics (BMKG) in Indonesia and inversions of global positioning system (GPS) data reveal clear seismic gaps to the south of the island of Java. These gaps may be related to potential sources of future megathrust earthquakes in the region. To assess the expected inundation hazard, tsunami modeling was conducted based on several scenarios involving large tsunamigenic earthquakes generated by ruptures along segments of the megathrust south of Java. The worst-case scenario, in which the two megathrust segments spanning Java rupture simultaneously, shows that tsunami heights can reach ~ 20 m and ~ 12 m on the south coast of West and East Java, respectively, with an average maximum height of 4.5 m along the entire south coast of Java. These results support recent calls for a strengthening of the existing Indonesian Tsunami Early Warning System (InaTEWS), especially in Java, the most densely populated island in Indonesia.

Introduction
Seismic gaps off the southwest coast of Sumatra, which pose a risk for generating future megathrust events, have been studied in detail (e.g., Refs.1,2,3,4). On the other hand, seismic gaps further southeast along the Sunda Arc adjacent to Java, the main island of Indonesia with a total population of more than 150 million people, have been less intensively studied. The regions along the southern coast of Java, e.g., Pelabuhan Ratu, Pangandaran, Pacitan, and Banyuwangi (see Fig. 1a), have grown rapidly in recent times and are prone to large earthquakes and their associated tsunamis, which can be devastating. In 1994 and 2006, tsunamigenic earthquakes of magnitude < 8 occurred near Banyuwangi (Mw 7.8), East Java7 and Pangandaran (Mw 7.7), Central Java8, respectively (Fig. 1), and the accompanying tsunamis killed a combined total of nearly a thousand people.

Figure 1
figure1
Regional setting and distribution of epicenters. (a) Map of the study area. Plate motion is from Altamimi et al.5. The bathymetry data were taken from ETOPO16. Inset shows the location of the study area (red rectangle) with respect to southeast Asia. (b) Distribution of epicenters of relocated earthquakes with magnitude ≥ 4.0. The earthquake data (2009–2018) were taken from BMKG. The focal mechanisms of events with M > 7.0 are plotted at ISC-EHB locations and are taken from the Global Centroid Moment Tensor (gCMT) solution catalog (https://www.globalcmt.org); (cf. Supplementary Fig. 2, i.e., all ISC-EHB locations from 1964 to 2016). Note that focal mechanisms are coloured according to gCMT depths, which are not always consistent with the ISC-EHB depths e.g. the 1994 Java earthquake, which is most likely shallow. Regions that lack seismicity (as approximately indicated by the red shaded areas on the map) are interpreted as seismic gaps. Black rectangles (A–C) indicate the location of vertical cross sections shown in Fig. 2. We intentionally compress the colour mapping so that all events below 50 km depth are dark blue such that it is more straight forwards to distinguish upper plate crust events from downdip interface events, and events in the oceanic plate from updip interface events.

Full size image
South of Java, Jurassic-age seafloor with a thick sediment cover is subducting beneath the edge of the Sundaland margin at the Java Trench (see e.g., Ref.9). The absence of recent great earthquakes may indicate that even more powerful tsunamigenic events along the south coast of Java are a potential threat. If this is true, then the release of effective early warnings needs to be a high priority, since most people living in high tsunami risk areas will have little time to evacuate. However, the presence of a seismic gap does not necessarily imply the accumulation of elastic strain, since slow slip events could be responsible for ongoing energy release10,11. While there is no evidence for slow slip along the Java Trench, this may be due to a lack of observations, such as could be acquired from seafloor geodetic investigations12. Nevertheless, while slow slip cannot be ruled out, recent studies13 have found evidence of tsunamigenic deposits along the coastline facing the Java Trench, which point to the occurrence of historic megathurst events.

In this study, we use new data taken from the Indonesian Tsunami Early Warning System (InaTEWS) catalog reported by BMKG, together with data from the International Seismological Centre (ISC) catalog, to investigate the potential for megathrust earthquakes and consequent tsunamis south of Java. From this combined dataset, we extract P- and S-wave arrival-times from 436 seismic stations at local, regional, and teleseismic distances in the period from April 2009 to November 2018 (Supplementary Fig. 1a). We limited the earthquake data to those events that have an azimuthal gap of less than 210°, following14, and at least 10 P- and S-phase arrival times. Using this dataset, we were able to accurately relocate a total of 1898 earthquakes with Mw ≥ 4.0 in the study region. The relocation was achieved using the teleseismic double-difference technique that is part of the teletomoDD method introduced by Pesicek et al.15, which also permits local and regional recordings of earthquakes to be included.

Besides the seismic data analysis, we also inverted 6 years of GPS data from 37 stations in Central and East Java to investigate slip deficits that can lead to future earthquakes. These results were combined with those of a previous study of West Java in order to generate a composite model of slip deficit rate for the whole of Java. The source areas and expected slip inferred from the GPS data inversion results are then used for numerical modeling of tsunami heights via finite difference solution of the long wave equation. Three different rupture scenarios are tested, with a focus on maximum wave height along the south coast of Java.

Results
Our earthquake relocation results show clear elongated zones, located between the coast of Java and the Java Trench, which lack seismicity and hence are identified as seismic gaps (Figs. 1b and 2 ). The approximate location of these gaps is highlighted by the red rectangles in Figs. 1b and 2 (see Supplementary Fig. 2 for a comparison plot that also includes all ISC-EHB events of Mw ≥ 4.0 from 1964 to 201616). These gaps are symptomatic of subduction zones which hold significant potential for great earthquakes; elsewhere, such as parts of offshore Sumatra (see Supplementary Fig. 3), where recent seismicity has filled the seismic gaps, large earthquakes are not expected. If it is assumed that the gap corresponds to a lack of earthquakes on the plate interface17 of the subducting slab, as described by the Slab2.0 model18, then the “locked” region of the subduction interface extends to a depth of between 20 and 30 km (Fig. 2), close to the base of the upper plate crust, which would be consistent with a typical seismogenic zone for large subduction zone earthquakes.

Figure 2
figure2
Cross sections of relocated earthquakes with magnitude ≥ 4.0. The locations of cross sections A–C are shown in Fig. 1b. The focal mechanisms of events were taken from the Global Centroid Moment Tensor solution catalog (https://www.globalcmt.org). Blue lines depict the plate interface of the subducted Indo-Australian Plate according to the Slab2.0 model18, while green and black lines depict the oceanic and continental Moho depths, respectively (taken from58,59,60). The thick red lines denote the approximate locations of seismic gaps, and are drawn to be consistent with Fig. 1b. Again, we compress the colour mapping so that all events below 50 km are dark blue as in Fig. 1b. Note that focal mechanisms are coloured in the same way as Fig. 1b.

Full size image
The epicentral shifts of relocated events are in general perpendicular (north–south direction) to the Java Trench (Supplementary Fig. 1b and c), which may be caused by the stations being mainly distributed to the north on Java15,19. Similarly, since all seismometers are placed on the surface above the earthquakes, there are also shifts in the vertical direction (Supplementary Fig. 4). Following the hypocenter relocations, there is a significant reduction in travel-time residuals as depicted by the histograms of relative residuals (Supplementary Fig. 5), which indicates a better travel time fit for the new locations. Statistical uncertainties of the hypocentral parameters, which are also produced by the relocation, are shown in Supplementary Fig. 6.

By comparing the observed deformation field with long term plate motion models, the GPS data inversion results are able to reveal the present day strain accumulation process, which likely reflects a longer term build-up of strain energy (Fig. 3). Where the observed GPS deformation is less than the plate motion (slip deficit), the areas are inferred to be likely sources of future earthquakes. The area of strongest slip deficit is south of West Java (Fig. 3), which may be a potential source for a megathrust earthquake20. The inversion of GPS data from Central and East Java undertaken in this study shows similar features, i.e., two zones with slip deficits, albeit of lower magnitude compared to the west, which is unsurprising considering the differences in GPS velocities between the two regions (Fig. 3). The first high-slip deficit zone is located on the shallower part of the fault off the south coast of Central Java. The second high-slip deficit region is in the deeper part of the megathrust seismogenic zone off the south coast of East Java.

Figure 3
figure3
Interplate coupling models. (a) Slip deficit/excess along the Java Trench derived from GPS data that reflects the segmentation of the megathrust to the south of Java. Left: model derived by Hanifa et al.20; Right: model produced by this study. Black squares are superimposed to indicate where the estimated uncertainty is lower than the absolute value of the predicted slip deficit rate. See Supplementary Fig. 7b for an uncertainty map based on the posterior covariance matrix. Colour scale depicts the estimated slip-deficit rate (red) and the slip-excess rate/afterslip (blue). Dashed lines are contours of the top of the slab from the Slab 2.0 model18. Green squares depict the locations of GPS stations used by Hanifa et al.20 to constrain the model south of West Java, and the blue squares denote the locations of GPS stations used in this study to produce the model south of Central and East Java. Arrows show GPS velocities relative to the Sundaland block reference frame. Blue arrows represent the GPS velocities derived in this study after removing the postseismic deformation of the 2006 Java tsunami earthquake. Green arrows are GPS velocities taken from Hanifa et al.20. Note that most vectors are aligned in the direction of current plate motion. This could be an indication of strong seismic coupling to the south of the study area. The red areas of slip deficit indicate areas with increased potential for a great earthquake. These regions may rupture in individual events or together in the worst-case scenario. Plate motion is taken from the ITRF2014 model by Altamimi et al.5. (b) Same as (a) but with the epicenter distribution shown in Fig. 1b overlaid on the slip deficit model.

Full size image
The assumption that the areas of large slip deficit will correspond to areas of large seismic slip during future large earthquakes may turn out to be an over-simplification. Examples from other regions reveal a complicated relationship between geodetic measurements and slip during earthquakes21. However, we still feel that it is a useful exercise to investigate this scenario, since it does provide a means to estimate potential tsunami heights in the event of a future great earthquake. The approach and assumptions we adopt are similar to those used for the Nankai trough, where areas of strong geodetic coupling are assumed to be areas of large slip during earthquakes22.

If we adopt the above assumption, then the area of high slip deficit may rupture separately or together during an earthquake. The area of the deficit zone south of West Java is equivalent to a Mw 8.9 earthquake, assuming a return period of 400 years (consistent with Harris et al.13 and Okal23). For the same return period, the area of high slip deficit in Central and East Java is equivalent to a Mw 8.8 earthquake, whereas if both areas rupture in a single earthquake, it would produce a Mw 9.1 event.

To assess the potential tsunami heights along the south coast of Java we conducted tsunami modeling using several different scenarios. Hypothetical megathrust segments are available from the National Center for Earthquake Studies of Indonesia (see Supplementary Fig. 9), but in this study we used megathrust segments from our GPS data inversion, which we regard as more realistic since we estimated the expected amount of slip. Here, we carried out tsunami modeling with three different megathrust scenarios: (1) western Java segment only (Mw 8.9), (2) eastern Java segment, i.e., to the south of Central and East Java, only (Mw 8.8), and (3) western and eastern Java segments (Mw 9.1). The results of Scenarios 1 and 2, along with initial water heights for all three scenarios, are presented in Supplementary Figs. 10–12. The worst-case scenario (Scenario 3) with a return period of 400 years can generate a giant earthquake of Mw 9.1 and a very large tsunami with a maximum height of 20.2 m near the small islands to the south of Banten, the westernmost province of Java, at ~ 105.5°E (Fig. 4). We note that the tsunami heights can be even higher than modeled when slumping occurs, as has been suggested in the case of the 2018 M 7.5 Palu strike-slip earthquake in Sulawesi, East Indonesia, where submarine landslides may have contributed to tsunami generation24.

Figure 4
figure4
Modeled tsunami heights along the south coast of Java. This model is based on the worst-case scenario in which the modeled tsunami sources off the south coast of Java rupture at the same time. (a) Combined modeled tsunami sources off the south coast of Java from Scenarios 1 and 2. (b) Maximum tsunami height throughout model region over duration of simulation. (c) Maximum tsunami height along the south coast of Java.

Full size image
Discussion
Okal23 presented a detailed study of the 1921, 1937 and 1943 intraplate earthquakes south of Java, and found that the Java subduction zone lacks large interplate thrust events for the entire era of instrumental seismicity. However, he also remarked that this does not exclude the possibility that larger earthquakes occur over recurrence periods longer than the instrumental history, thereby leaving open the possibility that megathrust events will occur along the Java Trench. The results of our study, based on the seismic and GPS data, show that in the scenario we develop, there is high potential for megathrust events off the southern coast of Java, as suggested by the observed seismic gaps depicted in Figs. 1b and 2. The locations of the seismic gaps appear broadly consistent with the areas of slip deficit along the Java Trench as determined from interplate coupling models derived from GPS data (Fig. 3).

As acknowledged previously, seismic gaps may be caused by slow slip events that do not manifest seismically10,11, and the recent < 8 Mw events in 1994 and 2006 may represent the upper limit of earthquake size along the Java Trench. However, in light of recent megathrust events such as the 2004 Sumatera and 2011 Tohoku earthquakes, determining maximum moment release based on historic recordings or models can produce conservative estimates, and all subduction zones of sufficient length should be regarded as possible hosts of megathrust earthquakes24. In the case of the Java Trench, its potential in this regard is supported by a recent study13 that found tsunami deposits at many sites along the coastline facing the Java Trench, which lead the authors to conclude that megathrust earthquakes occur with a return period of approximately 500 years. Consequently, we believe that our models represent a plausible scenario, but acknowledge that the potential for slow slip and complexities in the relationship between slip deficit and earthquake rupture may also play a role in determining the likelihood of future great earthquakes.

The results of our tsunami modeling, performed using the tsunami sources derived from the GPS data, i.e., the interplate coupling models, show that the worst-case scenario (Scenario 3), where the tsunami sources off the south coast of Java all rupture at the same time, produces a tsunami height up to 20.2 m and 11.7 m in West and East Java, respectively. These maximum tsunami heights are similar to those obtained from Scenarios 1 and 2, but the combined tsunami sources increase the average tsunami height along the south coast of Java to ~ 4.5 m (Fig. 4). We note that the larger value in the west may in part be a consequence of the slip deficit modelling undertaken by Hanifa et al.20, which did not account for the effects of post-seismic deformation following the 2006 Mw7.8 earthquake, and hence should be regarded as an upper limit. Nevertheless, even if maximum wave heights in West Java are similar to those in East Java, they would pose a risk to densely populated cities in the region such as Pelabuhan Ratu.

Our multidisciplinary study, which includes seismic and geodetic data analyses and tsunami wave height modelling, clearly reveal the presence of seismic gaps off the southern coast of Java that could be the source of future great earthquakes with tsunamigenic potential. Although this is only one possible scenario, with mitigating circumstances such as slow slip potentially reducing the likelihood and severity of such an event, it nevertheless seems prudent to support recent calls13,25 for additional submarine and sea level instruments for the relatively sparse InaTEWS network in south Java, to help protect the many people living in the coastal areas.

Materials and methods
Data sources
The earthquake data used in this study were taken from the BMKG and ISC data catalogues. The GPS data were obtained from the Geospatial Information Agency of Indonesia and the Ministry of Agriculture and Spatial Planning/Land Administration Agency as part of the Indonesian Continuously Operating Reference Stations network. Plate motion and the bathymetry data were taken from Altamimi et al.5 and ETOPO16, respectively.

Double difference earthquake relocation
We used the teletomoDD algorithm, which is an extension of the double difference tomography method26 to teleseismic distances15. Following Pesicek et al.15, in this study we kept the initial seismic velocity model fixed and used the relocation capabilities only. Travel times were calculated using a 3D regional seismic velocity model of the Indonesian region with a grid size of 1° × 1°27 and the ak135 global 1D model28 for regions outside Indonesia. We employed the pseudo-bending ray tracing technique29 adapted for use in a spherical coordinate system by Koketsu and Sekine30. This ray tracing method allows for the prediction of local, regional, and teleseismic P- and S-wave arrival-time data, which enabled us to incorporate both BMKG data and data recorded by regional and global networks. The initial number of earthquakes available in our catalogue is 2312. However, prior to relocation, we implement selection criteria to eliminate poorly constrained events. The selection criteria are: (1) the events have at least 10 P- and S-phase arrival times, and (2) the azimuthal gaps are less than 210° for local/regional stations in the Indonesian network. A total of 2046 events passed the selection process and were subsequently relocated using the double difference approach. A total of 20 iterations of the double difference algorithm were applied, which yielded 1,898 well located events (see Figs. 1b and 2) and 148 poorly located events that were discarded from the final dataset.

The distribution of seismic stations used in this study, the epicentral shifts following event relocation, and a Rose diagram highlighting trends in the epicentral shifts are shown in Supplementary Fig. 1. In Supplementary Fig. 2 we plot the hypocenters of all events of Mw > 4.0 from the ISC-EHB catalogue from 1964 to 201616, which illustrates that the seismic gaps we identify south of Java are still present for this much larger dataset. Supplementary Fig. 4 displays a comparison between the BMKG hypocenters and those resulting from the teletomoDD relocation, the hypocenter shifts, as well as along-dip-distance of hypocentral shift as a function of azimuth. Supplementary Fig. 5 shows histograms of relative residuals before and after relocation, respectively. Here, we note that the histograms were constructed using the relative residual data of event pairs as required in the teletomoDD technique15 and not the absolute residual data of each event.

To estimate the location uncertainties associated with teletomoDD hypocenter results, we performed a jackknife resampling analysis31,32. Following Tichelaar and Ruff33 and Halpaap et al.34, we created a number of resampled datasets by removing a fixed number of our input data. In our case, we created 100 datasets by randomly deleting 10% of the differential travel-times data. We re-ran the hypocenter relocation using these datasets and computed the standard deviations of the earthquake locations. The average horizontal and depth uncertainties are 3.3 and 5.3 km, respectively (Supplementary Fig. 6).

GPS data processing
We used GPS data from 37 stations (see Fig. 3) located in central and eastern Java from 2008 to 2014, of which 20 are international GNSS stations. GAMIT/GLOBK software35,36 was used to analyze the daily solutions of the GPS recordings. The processing strategy for the GPS data follows the approach described in our previous study37. Final solutions of the GPS analysis are in the International Terrestrial Reference Frame (ITRF) 200838.

Gunawan et al.39 pointed out that the mainshock of the 2012 Mw 8.6 Indian Ocean earthquake affected global tectonic displacements as far away as Java. Thus, the GPS daily solutions in this study are corrected for the coseismic displacements of the 2012 earthquake. Daily solutions were then transformed into the Sundaland block reference frame based on the transformation parameters of Altamimi et al.5. From these GPS data, we generated velocity estimates by applying linear regression at each GPS station.

In the western part of the study area, an Mw 7.8 tsunamogenic earthquake occurred in 200640. Previous studies have suggested that the area around the mainshock continued to deform following the rupture due to postseismic deformation (e.g., Refs.41,42). In most cases, the mechanism of postseismic deformation associated with viscoelastic deformation generates a broader deformation area than afterslip43,44,45.

Modelling studies37,46 have suggested that the postseismic deformation of the 2006 earthquake involved a long duration of afterslip and a viscoelastic relaxation that affected Java12. We removed the effect of the postseismic deformation of the 2006 earthquake at each GPS station by employing afterslip and viscoelastic modelling as proposed by Gunawan et al.37. Thus, the ‘corrected’ velocities at each GPS station become the final data used for further analysis. Using the corrected velocity at each GPS station, we can then conduct slip deficit/excess modeling.

Figure 3 shows a map of GPS velocities for Central and East Java derived in this study after removing the postseismic deformation of the 2006 Java earthquake, together with GPS velocities for West Java derived by Hanifa et al.20, which have not been corrected for postseismic deformation. Most vectors point in the direction of current plate motion, indicating strong seismic coupling to the south of Java.

Slip deficit/excess modeling
Using the corrected velocity at each GPS station, we analyzed the slip deficit/excess in the central-eastern part of Java using the ‘backslip’ concept to characterise interseismic deformation at subduction zones47. In our study area, tectonically stable locations for analyzing slip deficit/excess are not available. Thus, we used an analysis of baseline length changes to calculate the slip deficit/excess of the fault plane along the Java Trench20,48,49.

In our analysis, we constructed a fault plane of 660 km length and 210 km width, which was discretized into 30 km × 30 km fault patches. Based on the Slab2.0 model for megathrust geometry18, we employed a dip angle of 16° from the surface to 52 km depth, and a dip angle of 34° for greater depths. The fault strike is assumed to be 278°, while the rake is 270°.

We designed a network of baselines by connecting pairs of GPS stations in this region using the same approach adopted by Hanifa et al.20. From the 37 continuous GPS stations, we produced 83 baselines. Using the ‘corrected’ velocities, we calculated the baseline rate changes. In our inversion analysis, we generated Green’s functions for each baseline using an elastic half-space model50. Since all other parameters are defined, the only unknown parameters are the magnitude of slip deficit/excess. In our slip inversion procedure, we employed a priori information in the form of smooth spatial variations with free boundary conditions along the trench and no-slip conditions for the other three fault plane edges (east, west, and north). The slip distribution was then estimated using Akaike’s Bayesian Information Criterion (ABIC)51,52,53. Supplementary Fig. 7a shows the variation of ABIC as a function of the hyperparameter (a dimensionless quantity that controls the relative weighting between fitting the data and the prior smoothness constraints), and the location of the best-fit model.

Using GPS data located in the western part of Java, Hanifa et al.20 estimate slip deficit/excess off the southwest coast of Java. In this study, we combine their findings and our new findings in a single plot (Fig. 3a). The combined results show a significant slip deficit/excess distribution along the Java Trench, which can be compared to the distribution of seismicity (see Fig. 3b). In Fig. 3a we superimpose black squares in regions where the absolute value of the slip deficit rate exceeds the model uncertainty. In the case of the eastern segment, this information is derived from the posterior covariance matrix, the diagonal elements of which are plotted in Supplementary Fig. 7b; for the western segment, the corresponding information is supplied by the study of Hanifa et al.20. The difference between data observations derived from GPS data and predictions from the slip deficit model are plotted in two ways—as velocity vectors with respect to reference stations in Supplementary Fig. 7c and as baseline change rates in Supplementary Fig. 8.

Based on the above results, the primary regions of slip deficit appear to be robust. We note that combining the GPS data from Hanifa et al.20 with the GPS data we processed to produce a single slip deficit model may result in potential inconsistencies since we have removed the effect of the postseismic deformation of the 2006 earthquake at each GPS station by employing afterslip and viscoelastic modelling as proposed by Gunawan et al.37, whereas they did not attempt to account for the effects of this event. Indeed, Hanifa et al.20 suggest that southward motion of station CPMK (see Fig. 3) is evidence of ongoing afterslip related to this Mw 7.8 earthquake, although whether it occurs inside the mainshock rupture area or in the adjacent downdip area cannot be determined. The reduced amplitudes of the anomalies on the eastern section compared to the western section may in part be a consequence of not accounting for this afterslip.

In terms of spatial resolution, Hanifa et al.20 use fault patches of size 12.5 × 12.5 km, which is considerably smaller than ours, but synthetic recovery tests demonstrate that at depths between 30 and 70 km, resolution is ~ 60 × 60 km or better, whereas at depths less than 30 km, it increases to as much as 250 km along strike, and 100 km down dip. A similar pattern of model resolution would also apply to the central-eastern segment recovered in this study.

Tsunami modeling
Based on the slip deficit/excess modeling results from the GPS data, we modeled the tsunami height and inundation based on several scenarios using the TUNAMI modelling code of Imamura54 and Imamura et al.55. We prepared a set of bathymetric and topographic data to construct a rectangular grid of points in latitude (5° to 14°S) and longitude (103° to 116°E) (Supplementary Fig. 10) based on the General Bathymetric Chart of the Oceans (GEBCO) 15 arc-second interval datasets (https://www.gebco.net56). The model domain, which is transformed to Cartesian coordinates, has 3120 and 2160 nodes in the x (longitude) and y (latitude) directions, respectively, with an equal grid spacing of 463 m. The vertical wall boundary condition is used at the coast, which does not allow for the transfer of momentum flux. This is a common boundary condition for tsunami modelling, which prevents on-shore inundation54. We used the long wave equation of Imamura54, which was solved using finite differences, to model tsunami propagation from three different source scenarios with various slip distributions. The first scenario is defined by 720 segments in West Java (Scenario 1 with an estimated magnitude of Mw 8.9), the second by 154 segments in East Java (Scenario 2, with an estimated magnitude of Mw 8.8) and the third a combination of scenarios 1 and 2 with an estimated magnitude of Mw 9.1, which is referred to as Scenario 3. The various slip distribution sources were modeled using an elastic deformation model50 for each segment. It was assumed that all segments ruptured simultaneously without any consideration of the rupture speed or finite rise time (Fig. 4). The model was run for 5 h to obtain maximum tsunami height along the south coast of Java.

The results of tsunami modeling based on slip deficit/excess results from the GPS data described above are presented in Supplementary Figs. 11 and 12. The resulting tsunami heights along the south coast of Java from Scenario 1 show that the maximum tsunami height is likely to occur in the region between 105° and 106°E, i.e., at the small islands located ~ 11 to 15 km from the nearest coast line where tsunami height can reach up to 20.2 m. This scenario yields an average tsunami height of 3.23 m along the south coast of Java (Supplementary Fig. 11). Based on Scenario 2, a maximum tsunami height of 11.7 m can occur at 113.65°E along the south coast of East Java. The broad rupture zones in this region have resulted in roughly similar peak tsunami heights along the coast between 110°E and 114°E compared to further west, but with a lower average tsunami height of 2.43 m (Supplementary Fig. 12). Wave-height uncertainty is not straight forward to estimate, but our results are largely consistent with those from Horspool et al.57, who undertook a probabilistic tsunami hazard assessment of Indonesia, in which they use a different finite difference code, source rupture model and bathymetry (30-arc second model from GEBCO). While our model is more detailed, the basic pattern of peak wave-heights along the south coast of Java is similar, with the largest amplitudes occurring in the west and an average maximum wave-height along the entire coast of between 4 and 5 m.

Earthquake occurrence is ultimately controlled by tectonic stress load. Nevertheless, the 2019, Mw = 4.9, Le Teil earthquake in southern France occurred in an area where strain rates are relatively low. Human operations can produce increases in stress load and degradation of strength on nearby active faults, which raises the potential for failure. Here we present estimates of the rupture geometry and source directivity of the Le Teil earthquake based on differential synthetic aperture radar interferometry and seismic data. We find that almost two centuries of mass removal at a nearby cement quarry likely provided the required stress change to either induce the Le Teil earthquake, or hasten its occurrence by more than 100,000 years. We suggest that further mass removal in the area might lead to even stronger earthquakes, by activating deeper sectors of the same fault plane.

Introduction
Regional and local stress conditions driven by tectonic forces and, in particular, the value of the differential stress on the fault drives the occurrence of earthquakes. Nevertheless, large scale industrial activity might result in stress variation large enough to induce earthquakes or—added to the tectonic stress—to overcome the fault strength, advancing the time to the next expected rupture. Physical processes commonly considered capable of inducing or triggering seismic events by anthropogenic activities include underground volumetric changes, fluid pressure diffusion with/without fluid flow in rock fractures/pores, and thermal stress variations due to temperature gradients (e.g., ref. 1,2,3,4,5,6,7). Besides, a very limited number of cases also report about causal relationship between earthquakes and mass removing from Earth’s surface, related to quarry activity2,8,9,10.

On November 11, 2019, an MW = 4.9 earthquake rocked southeastern France, close to the small town of Le Teil and about 10 km from Montelimar. Four people were injured and hundreds of buildings damaged, some of which collapsed. The earthquake happened in the proximity of the NE–SW, southeast-dipping, St. Thomé-La Rouvière fault (LRf) system11, which marks the southeastern border of the Massif Central over almost 150 km12, in an area where intense rock extraction has been proceeding since the eighteenth century. The fault system is associated with the Variscan orogeny (more than 280 Ma) and during the Oligocene age (about 30 Ma) was characterized by extensional tectonics13. The region is characterized by a very low seismic activity rate, with maximum magnitude ranging between 3 and 4, as deduced from the seismic catalog of the French national seismic network RéNaSS (https://renass.unistra.fr/recherche: last accessed April 2020). Important historical earthquakes occurred in 1773 and 1873, about 30 km S-SE of Le Teil, with maximum intensity level IMAX VIII14. The current phase of tectonic deformation in the area, starting ~20 Ma, is characterized by NW-SE compression, coherent with the 140° direction indicated by the World Stress Map (http://www.world-stress-map.org; last accessed July 2020), and associated with a relatively low strain rate ~0.5 × 10−9 year−1 (ref. 15,16,17). Nevertheless, no evidence of cumulate compressional deformation has been detected along the ruptures associated with the 2019 earthquake18.

Based on the above piece of evidence, we analyzed the source characteristics of the Le Teil earthquake and investigated the possible link with the nearby industrial activities. Our results indicate that the extraction activity could have induced or at least triggered the Le Teil earthquake. In this latter case, we estimate a clock advance larger than 100,000 years.

Results
Geodetic data inversion
Hypocentral locations for the 2019 event provided by different institutions are quite scattered. The ones better constrained, being obtained from regional—rather than teleseismic—first arrivals travel times, are located a few kilometers southwest of Le Teil, at a depth shallower than 5 km (Fig. 1a; Table 1). The epicentral area is characterized by an intricate structural setting, with several faults trending approximately NE–SW, interconnected with minor NW–SE structures11,12. Coseismic ground ruptures18 (Fig. 1b) have only been detected along the northern end of LRf, close to Le Teil, where it trends about N50°. The fault mechanisms issued by French and international institutions (Fig. 1b; Table 1) indicate compressive source kinematics associated with a NE–SW trending plane, compatible with both the azimuth of the major faults in the area and the local stress field. The observed surface effects are located 1–2 km E–SE from the instrumental epicenters and are proximal to a large quarry complex where large volumes of limestone have been continuously removed for almost two centuries. This circumstance, along with the very low rate of seismicity in the region, raised public concern about the possible anthropogenic origin of the earthquake (e.g., https://www.nationalgeographic.com/science/2019/11/weird-earthquake-crack-france-geologists-buzzing/), in particular regarding extraction activities in the Le Teil quarry, located only 1 km east of the surface ruptures (Fig. 1a, b).

Fig. 1: The 2019 Le Teil earthquake.
figure1
a Map showing distinct locations of the 2019 earthquake (Table 1), quarry blasts and earthquakes from the RéNaSS catalog (https://renass.unistra.fr/recherche; last accessed April 2020), and the main geological lineaments12. b Perspective view with indication of the La Rouviere (LRf) and La Chade (LCf) faults, and coseismic ground ruptures18. The mechanism from SismoAzur (Table 1) is also reported. Both images are as of August 25, 2018.

Full size image
Table 1 Source parameters provided by several institutions for the November 11, 2019, Le Teil earthquake.
Full size table
We used space-borne differential synthetic aperture radar interferometry (DInSAR) measurements to derive the static ground displacements caused by the Le Teil earthquake. The deformed surface (Fig. 2) is elongated in the NE–SW direction, similar to the orientation of the LRf, with an extent of about 12 km2. Clear ground uplift results on the SE side of LRf, with a maximum over 10 cm, while a general subsidence results across the fault, with a slightly smaller maximum with respect to the uplift. Notably, a clear asymmetry is evident in the northern sector of the deformed zone, in correspondence of a minor fault located at the base of La Chade Hill’s NW flank12, calling for a more complex geometry of the ruptured area. Thus, to model the source geometry, we computed the analytical solutions for shear dislocation in an elastic and homogeneous half-space19, reproducing the coseismic surface deformation associated with the Le Teil earthquake. Our preferred solution (see “Methods” section and Supplementary Table 1) is characterized by almost pure reverse faulting on two distinct surfaces, F1 and F2, with an area smaller than 3.5 × 1.9 km2 and 1.8 × 1.9 km2, respectively (Fig. 2). F1 strikes 43.2°, with dip 52.1°, and coincides with the central sector of the LRf, while F2, oriented at 25.4° and dipping 68.1°, is located slightly northeast of F1 and exactly corresponds with the La Chade Hill fault (LCf). Both model dislocations are located within 1 km from the surface and the distributed slip model features two main slip patches, one on each of the two planes. The maximum slip values are 0.29 m and 0.21 m, respectively for F1 and F2, both located at depth of about 0.7 km.

Fig. 2: Modeling of the DInSAR data.
figure2
a Data, modeling results, and residuals for line-of-sight surface displacement for ascending (ASC) and descending (DESC) orbits DinSAR interferograms. The fault trace of the two retrieved rupture planes is indicated by magenta lines, while the black contour depicts the Le Teil quarry. b The dislocation resulting from the inversion of the ground deformation data is displayed in both perspective and plane view. Each pixel is 100 × 100 m2.

Full size image
Source directivity analysis
It is worth noting that the instrumental hypocentral locations do not appear to be compatible with the causative faults resulting from the geodetic modeling. Thus, in order to get a deeper understanding of the earthquake source, we also investigated the source directivity by analysing the spectrum apparent corner frequency of the seismograms recorded at 16 stations within 300 km from the source, at different azimuths. A bilateral rupture results, with the dominant direction at 241 ± 8° and a secondary one at about 60°, associated with considerably lower seismic moment release (see “Methods” section). Moreover, the ratio between the rupture velocity vr and the S-wave velocity is 0.5 ± 0.1, which indicates a rather slow rupture propagation velocity. These results put clear constraints on the location of the nucleation point, implying that the rupture likely nucleated either on the northern end of F1 or on the southern end of F2, i.e., in between the two main slip patches and about 1 km east of the instrumental epicentral locations (Fig. 1), and propagated on the two planes in opposite directions, at very shallow depth (within approximately 1 km). This latter feature is usually associated with seismicity induced/triggered by anthropogenic activity1,2,20

Estimation of the mass removal
The documentation of the possible link between the earthquake and the mass removal from the close Le Teil quarry requires a volume estimate of the mass removed from the Earth’s surface since the beginning of the extraction activity in 1833. To this aim, we reconstructed the topographic changes of the Le Teil quarry area by developing digital surface models (DSM) at various dates (Fig. 3a; see “Methods” section). To increase coherency and avoid large outliers, we split the whole period into a few intervals. We used archive stereo aerial image pairs from the Institute National de l’Information Géographique et Forestiére (IGN), for 1946, 1979, 2007, and 2011, the most recent available. In order to recreate the pre-extraction topography of the site, we used the Carte de l’État-Major that dates back to 1846–1857, the earliest available topographic map of a suitable scale (1:40,000). We determined the volume extracted up to 2011, during the distinct time periods, from the comparison of the point clouds extracted from the topographic data (Fig. 3b). The rate of volume removal has been increasing dramatically through time—also thanks to the technological progress—from about 100,000 m3/year, operated up to the middle twentieth century, to more than 1,000,000 m3/year, i.e., more than one order of magnitude, with a substantial acceleration in the last decades (see “Methods” section).

Fig. 3: Estimate of the volume removed from the quarry and Coulomb stress modeling.
figure3
a Digital Surface Model (DSM) of the considered area at successive times. b Computation of the rock volumes retrieved by numerically comparing the available DSM. c Coulomb stress change, computed for μ′ = 0.4, caused by the mass removed from the Le Teil quarry on the fault planes associated with the 2019 earthquake. The black contours in the rightmost panel outline the area with coseismic slip larger than 0.28 m for F1 and larger than 0.20 m for F2. d Normal and shear stress components of the Coulomb stress change for the whole analyzed period. The small black square indicates the point where the shear stress illustrated in Fig. 4 is computed.

Full size image
Stress change caused by the quarry activity
We attempt to quantify the stress change induced on the faults associated with the 2019 earthquake by the mass subtracted from the Le Teil quarry. For each analyzed time interval we estimated the equivalent vertical force distribution corresponding to the total extracted rock, with a grid spacing of 2 m, and used the Boussinesq’s solution of three-dimensional elastostatics to compute the stress change in terms of Coulomb failure function variation, ΔCFF = Δτ + μ′Δσn, on both model faults (Fig. 3c).

The cumulative ΔCFF is characterized by relatively large areas of high stress increase on both of the considered faults. In particular, a large patch of stress increase resulted on the northern half of the LRf, with maximum corresponding to 1.10 MPa, while the Coulomb stress increased on most of the LCf, reaching a maximum change of 1.15 MPa. These values are very similar to the stress drop Δσ = 1.3 MPa estimated for the 2019 earthquake (see “Methods” section). Remarkably, (1) the portions of the causative faults where the slip distribution resulting from the inversion of the geodetic data displays a locked segment at the surface (southern end of the LCf and northern end of the LRf) are associated with areas of negative or almost zero Coulomb stress change, and (2) the overall stress increase area is located right in between the two fault planes, in the middle of the major slip patches (Fig. 2). When considered with the result of the directivity analysis, this evidence further supports the location of the rupture nucleation in the central part of the surface deformed area, on any of the two planes, i.e., where the surface mass removal caused the maximum stress change (Fig. 3c, and about 1 km east of the epicentral location resulting from first arrival travel times (Table 1).

Discussion
Overall, our results pose specific questions on the possible effects of the anthropic activity on the earthquake occurrence. In particular, (1) did the mass removal induce or trigger the earthquake and, (2) in the latter case, what is the clock advance with respect to the time the event would have occurred under the tectonic stress load alone? The tectonic horizontal strain (shortening) rate in the area is ~0.5 × 10−9 year−1 (ref. 15,16,17), oriented N140°. By considering only the LRf, releasing most of the seismic moment during the Le Teil earthquake, this suggests that an earthquake on this fault could have occurred anyway sometime in the future but the quarry activity triggered it, hastening its occurrence. There is no information on past seismic events on this fault and no speculation can be done on the possible recurrence time of sizeable earthquakes associated with it. However, by assuming an average rigidity of G = 32 GPa for the crust, the horizontal stressing rate σ˙=Gϵ˙ associated with the mentioned shear strain rate ϵ˙ would be ~15 Pa/year. By considering the single plane solution, the projections of this stress rate on the fault correspond respectively to ~13 Pa/year and ~6 Pa/year for the normal σn and shear τ stress components. The estimated cumulative maximum Coulomb stress change on the fault due to the total mass subtraction is 1.10 MPa by 2011, corresponding to maximum normal Δσn = 0.87 MPa and shear stress Δτ = 0.67 MPa. By accounting for the uncertainty in the estimated volumes (see “Methods” section), these stress values can be considered reliable within ±10%. Noteworthy, considering that about 10% of the total stress change derives from the mass removal in 1833–1946, the larger uncertainty associated with the reconstruction of the initial reference topography (see Methods and Supplementary Information), would only affect the final stress calculation by <5%.

The shear stress value resulting from the quarry activity is comparable with the stress drop of the earthquake (~1 MPa), pointing to an anthropogenic origin of the seismic event21. In fact, these results allow stating that the rock extraction from the quarry likely have induced the 2019 Le Teil earthquake or, alternatively, triggered it by dramatically accelerating the loading of the fault and hastening its unlocking. Incidentally, we note that even considering the upper extreme for the stress drop (Δτ = 2.0 MPa, see “Methods” section), it would be of the same order of magnitude of the calculated shear stress change and the hypothesis of an anthropogenic origin for the earthquake is still strongly supported.

In case of triggering, the time advance can be estimated by dividing the cumulative stress change associated with the quarry activity by the tectonic stress rate22. About 111,000 years is the time required for the tectonic forces to load on the fault a stress amount similar to the change produced by ~180 years of rock extraction from the quarry (Fig. 4). However, in this computation we did not include the mass removal relative to the period 2011–2019—because this information is not available to us—thus the above conclusions represent a conservative estimate. Assuming for 2011–2019 the same average extraction rate calculated for the period 2007–2011 (and the same location), the total normal and shear stress change would be Δσn = 1.3 MPa and Δτ = 1.0 MPa, respectively, corresponding to a time advance of ~1.6 × 105 years, making the induction hypothesis even more realistic, in agreement with the geologic evidences suggesting that the LRf could have been inactive since million years18. Considering the remarkable increase in the number and the magnitude of the quarry blasts in the area in the last few years (Supplementary Fig. 1), the recent extraction rate could have been even higher than what assumed and the estimated stress load would be larger.

Fig. 4: Stress progression on the main fault.
figure4
The increment of the shear stress on the faults of the 2019 earthquake caused by the tectonic forces (blue line; exaggerated vertical scale), starting from the previous (unknown) earthquake, and by the Le Teil quarry activity (1 MPa; gray line). The anthropogenic shear stress is computed at the point marked by the small black square in Fig. 3. The total shear stress on the fault is represented by the red line. The horizontal gray line on top marks the fault strength.

Full size image
In addition to the static stress change, the above results cannot exclude that the dynamic shaking from the quarry blasts possibly could have had a role in contributing to trigger the event, either in terms of short-term dynamic stress (due to transient stress perturbation) or by material fatigue due the repeated shaking.

Finally, the unusual aspect ratio and the very shallow distribution of the coseismic slip, very similar to other cases of triggered earthquakes23, could be interpreted as an indication that the stress change associated with the quarry extraction was enough to overcome the fault strength at shallow depth, but not sufficient to exceed the fault resistance deeper than that. In the hypothesis of a linear increase of the fault strength with depth and especially if on deeper portions of the fault there is near-critical preexisting tectonic stress, additional future mass removal might trigger deeper slip, possibly causing a stronger earthquake than the one that occurred on November 11, 2019.

Methods
DInSAR data analysis
In order to investigate the ground displacements associated with the considered seismic event, we exploited the Differential Synthetic Aperture Radar (SAR) Interferometry (DInSAR) technique, which allows the analysis of surface displacements along the radar line-of-sight (LOS). The SAR data considered were acquired by the Sentinel-1 (S1) constellation of the Copernicus European Program. Benefiting from the short revisit time and the small spatial baseline separation of the S1 constellation, we generated several coseismic differential interferograms (Supplementary Table 2) with a spatial sampling of about 15 m following an averaging operation (multilook) in the azimuth direction to reduce the speckle noise. Among the generated interferograms we selected those less affected by undesired phase artifacts (atmospheric phase delays, decorrelation noise, etc.) for the seismic source modeling discussed in the following section, thus preserving good spatial coverage and interferometric coherence. In particular, the employed S1 data pairs were acquired on November 6–12, 2019 (Supplementary Fig. 2A), and on October 31 and November 12, 2019 (Supplementary Fig. 2B) along the ascending (ASC) and the descending (DESC) orbits, respectively. On both interferograms, several fringes located near the epicentral area are clearly visible; note that each fringe corresponds to a LOS displacement of about 2.8 cm (i.e., half of the employed S1 C-band wavelength λ = 5.546 cm). Subsequently, starting from the selected interferograms, we generated their corresponding LOS displacement maps (Fig. 1a) through a phase unwrapping operation24.

By superimposing the fault traces on the selected pair of interferograms (Supplementary Fig. 2C, D and Fig. 1d) it is evident that the deformed area, extending for about 12 km2, is elongated in the NE–SW direction, very similar to the orientation of the LRf. Moreover, a clear asymmetry is clearly visible in the northern sector of the deformed zone, in correspondence of a minor fault located at the base of La Chade Hill’s NW flank (Supplementary Fig. 2E, F), suggesting a complex geometry of the ruptured area. This is also evident in the map of the vertical component of the retrieved deformation pattern (Supplementary Fig. 3A) that we computed from the unwrapped interferograms, together with the East-West deformation map (Supplementary Fig. 3B). Note that the maximum uplift is about 11 cm while the amplitude of the subsidence is appreciably smaller, with a maximum displacement of about 4 cm. For the horizontal displacements, the area affected by westward motion is rather extended, with a maximum value of about 8 cm, while eastward motions are more concentrated on the SW side of the LRf and shows a maximum displacement of about 7 cm.

Surface deformation data modeling
In order to retrieve the fault parameters, we jointly inverted the DInSAR displacements retrieved from ASC and DESC orbits by applying a consolidated two-step approach that consists of a nonlinear optimization to constrain the fault geometry, assuming a uniform slip, followed by a linear inversion to retrieve the slip distribution on the fault plane25. We modeled the LOS displacements retrieved from the DInSAR interferograms with a finite rectangular dislocation in an elastic and homogeneous half-space19, also applying a compensation for the local topography26 and assessing possible offsets and linear ramps affecting the DInSAR measurements. Moreover, data were preliminarily resampled over a regular grid (70 m spacing in all the considered area) to reduce the computation load. Starting from a nonlinear inversion algorithm based on the Levenberg–Marquardt least-squares approach, we searched for the source parameters of one or two rectangular dislocations with uniform slip and, thanks to multiple random restarts implemented within the approach, it was possible to catch the global minimum during the optimization process.

The second step of our modeling is represented by the linear inversion process with the computation of the nonuniform slip distribution, in order to have a more accurate estimate of the slip distribution along the fault plane. In particular, the linear inversion was performed by using as starting model, in terms of dimensions and orientation, the fault obtained from the previous nonlinear inversion discretized into 0.1 × 0.1 km2 patches and inverting the following system:

[dDInSAR0]=[Gk⋅∇2]⋅m,
where dDInSAR represents the DInSAR displacements vector, G is the Green’s matrix with the point-source functions, m is the vector of slip values for each patch (initially assumed as the value resulting from the nonlinear inversion), and ∇2 is a smoothing Laplacian operator weighted by an empirical coefficient k to guarantee a reliable slip varying across the fault. The choice of the parameter k depends on the compromise between the data fit and the smoothness of the slip distribution. We tested several values and selected k = 0.007, since appreciably higher residuals resulted for k ≥ 0.01 and similar residuals but inconsistent slip values (larger than 70 cm), with too rapidly varying slip distribution, resulted for k ≤ 0.004. Further constraints were introduced by imposing nonnegative slip (reverse slip only) values obtained via nonlinear inversion.

The surface deformation derived from the interferometric measurements acquired along ASC and DESC orbits reveals a spoon-like geometry, characterized by a NE–SW striking main distinctive displacement pattern (Supplementary Fig. 2). Thus, we first investigated solutions associated with homogeneous dislocation on a single planar source for which all source parameters were set free during the nonlinear inversion. Then, keeping the plane obtained in the geometry inversion fixed, we searched for the best slip distribution. The preferred solution (Supplementary Table 1) consists of a 4.1 × 1.0 km2 reverse fault, oriented N50° and dipping 62.3° southeast, with rake 116.5° and dislocation characterized by two separate major patches, located respectively north and south of the quarry, with a maximum slip in excess of 0.3 m (Supplementary Fig. 4). Although the single fault solution accounts for most of the observed DInSAR data, it is associated with large residuals, comparable to the maximum surface deformation (Supplementary Fig. 4). Also, it is worth noting that this solution does not align with any, and actually crosscuts all the faults mapped in the area. Thus, considering these observations, we tested a composite solution, with two fault planes. Similar to what was done for the single fault, we first searched for the best geometry for the two planes, by means of nonlinear inversion with uniform dislocation, and then solved for the slip distribution on the two fault surfaces with fixed geometry by linear inversion. Based on the features of the DInSAR data described above and on the local geology11,12, we tested several positions for the two faults in the uniform slip, nonlinear inversion, always keeping free strike, dip, rake (uniform for each plane), and dislocation. Eventually, we obtained solutions (Supplementary Table 1) noticeably reducing the residuals and, most importantly, compatible with the faults observed at the surface (Fig. 2b and Supplementary Figs. 2 and 3). The two planes coincide respectively with the central sector of LRf and to a structural lineament at the base of the La Chade Hill, both supposed to be SE dipping11, where the quarry is located. The preferred solution is characterized by a slip distribution shallower than 1 km depth. In particular, for the plane F1 the solution displays a 3 km-long, two-lobed patch with maximum slip of 0.29 m located on the northern half of the fault, while a maximum slip of 0.21 m results for F2, located approximately at the center of the fault.

Finally, as for the uncertainties associated with the slip solution we report the standard deviation (Supplementary Fig. 5) as obtained from the model covariance matrix, following an approach25 that accounts also for the noise covariance.

Source directivity analysis and stress drop estimate
We studied source directivity by using a simplified version of the directivity function Cd (ref. 27) for a bilateral linear rupture model:

Cd=12(1+e)2(1−αcosϑ)2+(1−e)2(1+αcosϑ)2−−−−−−−−−−−−−−−−−−−−−−−⎷,
(1)
where ϑ is the angle between the ray leaving the source and the direction of rupture propagation φ (ref. 28), and α is the Mach-number, that is, the ratio between the rupture velocity vr and the S-wave velocity. The percent unilateral rupture e parameter is defined as (2L′ − L)/L, where L is the total rupture length and L′ is the length of the dominant rupture29. A value of e = 1 corresponds to a unilateral rupture, whereas e = 0 corresponds to a bilateral rupture.

The effect of the directivity on the source spectrum is to increase the corner frequency at those stations located in the same direction as the rupture propagation and to decrease the corner frequency in the opposite direction (e.g., ref. 30). This effect can be modeled assuming that the apparent corner frequency is given by fca = fc Cd with fc indicating the actual corner frequency and fca the corner frequencies at various azimuths estimated from the source spectrum.

We retrieved waveforms corrected by the instrumental response at 22 stations from the Réseau Sismologique et Géodesique Français (http://seismology.resif.fr/#WelcomePlace; last accessed April 2020) (Supplementary Fig. 6A). We filtered all the waveforms in the frequency band 0.01–20 Hz. First, we discarded the stations with a low signal-to-noise ratio, which resulted to be poor at all the stations located at an elevation higher than 900 m, reducing the number of stations to 16. Then, we windowed the waveforms by cutting from 2 s before the manual S-wave picking to 6 s after. We applied a 5 per cent cosine taper function and zero padding before computing the Fourier amplitude spectra. The spectra were then smoothed by applying an average moving window with a four-point half width. Finally, we computed the S-wave displacement spectra from the modulus of the three components velocity or acceleration spectra by dividing the spectra by 2π or 4π2, respectively.

We assumed an ω−2 theoretical source spectrum model31, which is given by:

S(f)=Ω01+(ffc)2,
(2)
where Ω0 is the long-period spectral amplitude, f the frequency, fc the corner frequency. As for the anelastic attenuation we assumed the model A(f,T)=e−πfT/Q(f), where Q(f) = Q0f n and T is the travel time of the S phase. Using Eq. (2), together with the attenuation model, we fit the observed spectra through a grid search approach, to infer Ω0, fc, Q0 and n. As for Ω0, we normalized the spectrum and explored the range (0.7, 1.3), while the range of exploration for fc was (0.1, 2.0). Finally, we explored Q0 in the range (0,300) and n in the range (0, 2.0). The parameter Ω0 is then used to compute the seismic moment32 through the formulation:

Mo=4πρc3RΩ0FRθφ,
where R is the hypocentral distance, ρ is the density, assumed here 2690 kg m−3; and c is S-wave velocity assumed to be 3.5 km s−1. Rθφ is the average S-wave radiation pattern assumed to be 0.7 and F is the free-surface coefficient (fixed to 2). As for the uncertainty on each inferred parameter we used an approach33 providing confidence intervals based on jack-knife variance analysis. The computed fc as function of the station azimuth are finally fit by using the Cd function and the nonlinear Levenberg–Marquardt least-squares algorithm.

The observed displacement spectra together with the best-fit models are shown in the upper panels of Supplementary Fig. 6B. The average seismic moment value is 3.4 × 1016 (2.4 × 1016, 4.9 × 1016) N m corresponding to MW = 4.9. As for the anelastic attenuation, we found that a Q frequency independent model (i.e., n = 0) provides the best fit, with Q0 = 190 (193, 198). The estimated corner frequencies are shown in the lower panel of Supplementary Fig. 6B as a function of the station azimuth. The result clearly indicates at least one range of azimuths where the fc value increases with respect to the other directions. The fit with the Cd function, which is shown in the same panel, provides an e-value of 0.3 ± 0.1 indicating a bilateral rupture and a Mach-number of 0.5 ± 0.1 suggesting a rather low rupture propagation. The dominant rupture direction is at 241 ± 8° while the secondary direction is at about 60°. Using the average value of the estimated corner frequencies corresponding to 0.6 (0.5, 0.7) Hz and the seismic moment, we computed the static stress Δσ = 0.44 M0/r3, with the source radius given by r = 0.37vS/fc (ref. 28), being vS the S-wave velocity. We obtained r = 2158 (2044, 2846) m and Δσ = 1.3 (0.9, 2.0) MPa.

Calculation of the rock volume extracted from the quarry
We used multi-temporal DSM to estimate the removed volume of rock in the Le Teil quarry. Topographic map resolution, quality, and accuracy varies a lot with time, so a more robust method of change detection using high-resolution topography from stereo aerial imagery is preferred. However, the Le Teil quarry was established in 1833 and this technique is only available for the modern era. Thus, distinct methods must be used for the different time periods.

For the recent period, we used scanned stereo aerial images of the study area, available from the Institute National de l’Information Géographique et Forestiére (IGN). We used archive stereo aerial image pairs for 1946, 1979, 2007, and 2011 (Supplementary Table 3). We extracted DSM from stereo imagery using MicMac software34, following the procedure illustrated in Supplementary Fig. 7. For each group of stereo images, tie-points between images and camera frame/lens parameters were calculated. Using ground control points, we performed bundle adjustment and refinement of the camera calibration. Ground control points were picked from the latest IGN orthophoto map (coordinates in UTM zone 31 north, WGS84) and elevation values were extracted from ALOS Global Digital Surface Model. Then, DSM and orthophotos were produced. A point cloud was extracted from the Malt DSM and colored with RGB values from the orthophoto map (Supplementary Fig. 7). A detailed photogrammetric point cloud of 2007 covering a much larger area is available from the OpenTopography facility (https://doi.org/10.5069/G9BC3WQ4; last accessed April 2020).

Incidentally, we remark that there is a strip of images dated 1932 available from IGN, but processing produced many artifacts due to scanned film’s poor preservation and noise. Coregistration with 1946 data was also poor, with large residuals; thus, we decided not to use the 1932 dataset. We did not use the most recent set of digital aerial images provided by IGN (dated 2013), as the poor radiometric quality of the files leads to a low quality matching over the quarry area, thus rendering the dataset unusable for terrain change detection.

In order to estimate the initial reference topography of the site as best as possible, we searched for the earliest available topographic map on a suitable scale. We used the Carte de l’État-Major-feuile Privas S.O. (Supplementary Fig. 8), a map compiled between 1846 and 1857 at a scale 1:40,000. We georeferenced a high-resolution scan obtained from IGN (https://www.geoportail.gouv.fr/donnees/carte-de-letat-major-1820-1866; last accessed April 2020). A concise description of the main map-series features and how to spatially process each map sheet is also available35. As the map does not provide detailed and accurate contour lines, we extracted a dense set of elevation contours from the 1946 DSM. These contours were clipped at the maximum extent of quarry boundaries traced from the 1946 orthophoto (Supplementary Figs. 8 and 9). Using the 1846–1857 map as a reference for general relief representation and taking into consideration the geomorphologic features (Rhône river escarpment, drainage, and ridgelines) of the area around the quarry, contours were traced manually in order to fill the blank area and reconstruct the 1833 relief. By assuming for the reconstructed topographic height an uncertainty of 10 m over the whole quarry area as of 1946 (~300,000 m2), the uncertainty in the volume removed in the period 1833–1946 (larger than 11,000,000 m3) deriving from the procedure of reconstruction of the initial topography would be <30%.

Starting from the evolution of the topography, we estimated the volume of the mass progressively removed from the quarry. Instead of comparing the first and last DSM available, in order to increase coherency and avoid very large outliers we split the analysis into intervals: 1833–1946, 1946–1979, 1979–2007, and 2007–2011. Original DSM raster files were clipped and resampled into a common pixel size (3 m for 1833–1946 and 2 m for the rest) and then converted into point clouds. Point clouds were co-registered using the ICP matching tool from CloudCompare software (http://www.danielgm.net/cc; last accessed April 2020) and then each pair was processed with the Multiscale Model to Model Cloud Comparison (M3C2). This technique computes the local distance between two-point clouds along the normal surface direction which tracks 3D variations in surface orientation36. M3C2 distance raster files were cropped using the quarry boundary traced manually from orthophoto maps for each period, and removed volume (Supplementary Table 4. The uncertainty in the determination of the removed volume for each period is also reported) was calculated using raster statistics.

Boussinesq’s solution of 3-D elastostatic loading
We adopted the analytic solution in Cartesian coordinates (x1, x2, x3) of the three-dimensional elastostatics for the response of a semi-infinite solid (x3 ≥ 0) to an arbitrary normal load P0 on its boundary37. We considered the displacements and the stress components given the shear modulus μ and the Poisson ratio ν. If P0 is applied at (x01, x02, x3) then the displacement components in a generic point (x1, x2, x3) are given by:

u1=P04πμ(x1−x01)R[x3R2−(1−2ν)1R+x3],
u2=P04πμ(x1−x02)R[x3R2−(1−2ν)1R+x3],
u3=P04πμ1R[x23R2+2(1−ν)],
where R=(x1−x01)2+(x2−x02)2+x23−−−−−−−−−−−−−−−−−−−−−−−−−√. The components of the displacement can be used to compute the strain tensor ε and the stress tensor σ in the same point (x1, x2, x3). Under the hypothesis of infinitesimal deformation and for isotropic medium, εij = 1/2(dUi/dxj + dUj/dxi) and σij = λδijεkk + 2μεij, where λ is the second Lame’s parameter and δij the Kronecker delta. In particular, for the application presented in this study we used the six components of the stress tensor, which have the following expressions:

σ11=−Po2πR2{3(x1−x01)2x3R3−(1−2υ)[x3R−RR+x3+(x1−x01)2(2R+x3)R(R+x3)2]},
σ22=−Po2πR2{3(x2−x02)2x3R3−(1−2υ)[x3R−RR+x3+(x2−x02)2(2R+x3)R(R+x3)2]},
σ12=−Po2πR2(x1−xo1)(x2−xo2)[3x3R3−(1−2υ)(2R+x3)R(R+x3)2],
σ13=−3Po2πR5(x1−x01)x23,
σ23=−3Po2πR5(x2−x02)x23,
σ33=−3Po2πR5x23.
In order to quantify the effect of the removal of the rock mass from the quarry on the prescribed fault, we assumed that extraction operation is equivalent to the application of a set of vertical forces P0 = h·dA·ρ·g (being h the height of the eroded rock column computed from the DEM, ρ the rock density, g the acceleration of gravity and dA the elementary area of the DEM), at the surface of the investigated volume. Given the linearity of the model, the net effect on the fault in terms of σij is obtained by summing the contributions of the single forces. By decomposing σij in its normal component Δσn (assumed positive if the fault is unclamped) and shear component Δτ (assumed positive in the direction of the slip) along the fault and assuming a given value of the fault effective friction coefficient μ′ we computed the Coulomb stress change ΔCFF = Δτ + μ′Δσn. Specifically, we investigated three values of μ’ = 0.4, 0.5, 0.6 (Supplementary Fig. 10), generally assumed as plausible effective friction coefficient for natural faults38,39 and minor differences resulted in the maximum values, while no change in the general ΔCFF pattern. Conservatively, in order to estimate the effect of the quarry activity on the faults associated with the Le Teil earthquake, we used the results for μ = 0.4 (Fig. 3c), associated with the lower maximum value.

Tectonics and climate-driven surface processes govern the evolution of Earth’s surface topography. Topographic change in turn influences lithospheric deformation, but the elementary scale at which this feedback can be effective is unclear. Here we show that it operates in a single weather-driven erosion event. In 2009, typhoon Morakot delivered ~ 3 m of precipitation in southern Taiwan, causing exceptional landsliding and erosion. This event was followed by a step increase in the shallow (< 15 km depth) earthquake frequency lasting at least 2.5 years. Also, the scaling of earthquake magnitude and frequency underwent a sudden increase in the area where mass wasting was most intense. These observations suggest that the progressive removal of landslide debris by rivers from southern Taiwan has acted to increase the crustal stress rate to the extent that earthquake activity was demonstrably affected. Our study offers the first evidence of the impact of a single weather-driven erosion event on tectonics.

Introduction
It is well established that tectonics and climate influence the evolution of the Earth’s surface by modulating the rate and pattern of erosion and sedimentation1,2. In turn, theoretical predictions and numerical models suggest that changes of surface topography by surface processes can promote tectonic deformation over geological times3,4,5 (1–10 Myr), enhance fault slip over intermediate time scales6,7,8,9 (1 kyr–1 Myr), and induce sufficient static stress changes over a seismic cycle (1–1,000 year) to trigger earthquakes10. However, the influence of ongoing surface processes on tectonics has not been directly observed. Over seasonal timescales, surface (un)loading induced by rainfall or snow can modulate local to regional seismicity11,12,13. Here we ask if a single erosional event can have a discernable effect on seismogenic processes, which dominate deformation of the Earth’s upper crust. Both large-magnitude earthquakes and extreme rainfall events can trigger instantaneous and widespread landsliding, driving the export of millions of tons of sediment from mountain areas over periods of months to years2,14. At these timescales, geophysical methods allow monitoring of changes in earthquake activity associated with erosional perturbations. Compared to large-magnitude earthquakes, rainfall events do not directly trigger aftershock sequences (even if surface (un)loading can modulate seismicity), which could preclude the observation of a seismicity change induced by erosion. We therefore focus in the following on detecting seismicity changes associated with an erosional perturbation induced by a rainfall event.

Results
Landslides and erosion triggered by typhoon Morakot in Taiwan
For an example of an erosional perturbation, we consider typhoon Morakot, which made landfall in Taiwan from 7 to 9 August 2009. It delivered up to 3 m of precipitation in 3 days (Fig. 1), the largest recorded rainfall event in Taiwan in the past 50 years15. The typhoon triggered more than 10.000 landslides (see “Methods” section) in mountainous southwest Taiwan, where cumulative rainfall exceeded ~ 1 m (Fig. 1, Supplementary Fig. S1). In this area of ~ 7,000 km2 (hereafter the landsliding zone), that accounts for ~ 99% of the 1.2 km3 of total landslide volume16, the landslide spatial density ranges between 4 and 22 km-2 (see “Methods” section, Supplementary Fig. S2). The equivalent average erosion induced by these landslides is ~ 17 cm, which corresponds to ~ 10–100 years of erosion at the decadal average rate2. Most triggered landslides were connected to the river network17, which has led to a sharp increase of suspended sediment export after Morakot18,19. Consistent with geomorphological observations after the 1999 Mw 7.6 Chi-Chi earthquake20, enhanced sediment removal persisted for > 2 years18,19, although export of the coarse fraction of landslide debris may take decades or more21. The exact volume of sediment export is difficult to estimate, but the landsliding zone must have undergone a progressive surface mass unloading after one of the largest weather-driven erosion events on record. Despite a very likely large uncertainty, we roughly estimate that about 20–50% of the 1.2 km3 of landslide volume was exported of the landsliding zone after typhoon Morakot over the time period 2009–2012 (see “Methods” section).

Figure 1
figure1
Morakot-driven rainfall and landslides in Taiwan. (a) Hillshaded map of cumulative rainfall during typhoon Morakot (7–9 August 2009), obtained by interpolation of data from local weather stations (colored dots). (b) Digital elevation model of Taiwan with location of mapped landslides triggered by typhoon Morakot. Circle size and color indicate the surface area of a landslide, while the magenta line delimits the area with highest spatial density of landslides (see “Methods” section, Supplementary Fig. S2), referred to as the landsliding zone. Solid and dashed red lines indicate active thrust and strike-slip or normal faults, respectively22. Other less well identified faults exist inside the range27. (c) Probability density distribution of the surface area of landslides triggered by typhoon Morakot for areas greater than 10 m2. Maps were performed using Matlab R2019b.

Full size image
The landsliding zone belongs to a tectonically active region and is bounded in the east and west by several identified active thrust faults22. Thrust faults located in the western foothills have a dip angle between 10° and 30° and merge at depth, probably around ~ 10–15 km, into a basal decollement beneath the range22,23. In the east, the Longitudinal Valley fault has a dip angle ~ 45°–60°. Together, these faults accommodate ~ 40 mm year−1 of shortening, which is about half of the total convergence rate across the Taiwan plate boundary24. In addition, less well constrained faults are located beneath the range, as testified by the frequent seismicity observed in Central Taiwan.

Temporal changes in seismicity after Morakot
To determine how the erosional unloading due to typhoon Morakot may have impacted fault dynamics, we analyze the evolution of shallow (< 15 km) seismicity in Taiwan after it made landfall. Because the expected stress change is small compared to background tectonic loading at seismogenic depth10, we focus on detecting changes in the statistics of recorded seismicity, such as the earthquake frequency, seismic moment rate and the b-value of the Gutenberg–Richter earthquake size distribution (see “Methods” section), rather than on individual events. We use the seismicity catalogue of the Central Weather Bureau of Taiwan, which includes > 340,000 earthquakes during the period 1995–2015 over Taiwan island.

First, we assess the time evolution of earthquake statistics using a temporal sliding window of 1,001 earthquakes (see “Methods” section). Results show a stepwise increase of the frequency of shallow (< 15 km) earthquakes in the landsliding zone after Morakot (Fig. 2, Supplementary Fig. S3). Although this frequency increase is orders of magnitude lower than after the Chi-Chi earthquake, it is observed both for earthquakes with magnitude above the completeness magnitude (from ~ 0.8 to ~ 2 earthquakes per day) and for all recorded earthquakes (from ~ 5 to ~ 10 earthquakes per day). The increase of earthquake frequency during the 2.5 year after Morakot has a probability of 1 (see “Methods” section, Supplementary Fig. S4). The probability is still significant, at the 95% confidence interval, when considering a frequency increase by a factor ~ 1.2–1.5. Except for the regional seismicity rate increases due to the Chi-Chi earthquake, this is the only significant increase in earthquake frequency, over a period of 2.5 year, observed over the investigated period (1994–2013).

Figure 2
figure2
Time evolution of seismicity in Taiwan relative to typhoon Morakot. (a) Time evolution of frequency of shallow (< 15 km) earthquakes. The thick and thin blue line indicates the frequency of all earthquakes and of earthquakes greater than the completeness magnitude, respectively, inside the landsliding zone. The magenta line indicates the frequency of earthquakes inside the landsliding zone with a magnitude greater than a conservative value of 2.4 for the completeness magnitude. The thin grey line indicates the frequency of all earthquakes outside the landsliding zone. (b) Time evolution of the b-value of the Gutenberg-Richter law inside (heavy blue line) and outside (light grey line) the landsliding zone (see “Methods” section, Supplementary Fig. S1). (c) Gutenberg-Richter law fits over the distributions of cumulative earthquake numbers in the landsliding zone as a function of earthquake magnitude during the 2.5 years before (yellow) and after (green) typhoon Morakot (see “Methods” section).

Full size image
Moreover, the increase in earthquake frequency after Morakot is associated with an increase in the b-value from 1.18 ± 0.1 to 1.28 ± 0.1 (Fig. 3a). Both increases have a step-like shape, which lasts for at least 2.5 years (Supplementary Figs. S5, S6) and do not follow an Omori-type inverse law, which describes the temporal evolution of aftershock sequences. Because the seismometer network used to detect earthquakes remained similar in the time period January 2007 to December 2011 (see “Methods” section, Supplementary Fig. S7), we restrict our comparison to the time period from 2.5 years before to 2.5 years after Morakot. More instruments were added, mainly in North Taiwan, at the beginning of 2012, which explain why the frequency of earthquakes remains high in the landsliding zone after 2012, despite a decrease of the b-value towards its pre-Morakot value. Using a conservative and constant value for the completeness magnitude of 2.4 (see Fig. 2, Supplementary Fig. S3), we observed that earthquake frequency decreases to pre-Morakot values after about 2.5. The increase of the b-value in the landsliding zone after Morakot is found for different fitting methods of the Gutenberg-Richter law and sampling methods associated with the sliding time window (see “Methods” section, Supplementary Figs. S5, S6) and therefore deemed robust.

Figure 3
figure3
Change in b-value and depth of earthquakes after typhoon Morakot. (a) Notched whisker plots of b-value estimates for 2.5 years before (yellow) and after (green) typhoon Morakot inside the landsliding zone show the median (red line), mean (dot), 25th and 75th percentiles (box limits), whisker lengths (dashed lines) and outliers (purple crosses) of the b-value. Notches display the variability of the median between samples. (b) Histograms of earthquake depth during the 2.5 years before (yellow) and after (green) typhoon Morakot in the landsliding zone. Solid and dashed lines indicate depth-distribution for earthquakes of all magnitudes and magnitudes greater than the completeness magnitude, respectively. (c) Depth distribution of the ratio of the number of earthquakes in the 2.5 years after typhon Morakot, nafter, over the number of earthquakes in the 2.5 years before, nbefore. The blue line indicates results considering all earthquakes, the black line indicates results considering the reference declustered catalog and the grey lines indicate results obtained using the 50 declustered catalogues, resulting from a Monte-Carlo sampling of the model parameter space (see “Methods” section).

Full size image
In addition, considering all earthquakes during the 2.5 years before and after Morakot gives b-value estimates of 1.17 ± 0.03 and 1.31 ± 0.04 (Fig. 2c), respectively, similar to the values obtained by averaging the temporal b-value signal (Fig. 3a). We observe that the increase in earthquake frequency and b-value in the landsliding zone after Morakot coincides with an increase in the number of shallow earthquakes at depths < 15 km (Fig. 3b,c). Moreover, the increase is more pronounced closer to the surface and reaches a factor 2 to 3 in between 0 and 5 km of depth. We also observe a secondary peak at greater depth, 15 to 25 km. However, the rate of seismic moment release remains low after typhoon Morakot, and potentially lower than before (Supplementary Fig. S3). Crucially, earthquakes outside the landsliding zone do not show a significant temporal increase of both their frequency and b-value after Morakot.

Seismicity changes are not associated to earthquake clustering
These temporal changes in earthquake statistics after Morakot are determined from an undeclustered earthquake catalog. However, using a declustered catalog (see “Methods” section) also leads to similar changes in earthquake frequency and in its associated probability, b-value and depth-distribution after Morakot (Fig. 3c, Supplementary Figs. S9, S10). Moreover, this result is not limited to a single parametrization of the declustering algorithm and appears robust for all the acceptable combinations of declustering parameters. For instance, the increase in the number of earthquakes after Morakot at 15 to 25 km of depths is fully removed when considering any of the resulting declustered catalog, while the shallow peak remains (Fig. 3c). This demonstrates that these seismicity changes at shallow depths are not associated with triggering processes by large mainshocks, or by other earthquakes. In addition, based on comparisons between the observed earthquake catalog and synthetic catalogs that share the same average properties, we demonstrate that the observed changes in earthquake frequency and b-value after Morakot, in the landsliding zone, depart statistically from random temporal changes (Supplementary Fig. S12).

Spatial changes in seismicity after Morakot
To assess how the chosen delimited area affects our results, we compute the change in the spatial pattern of the frequency and b-value of shallow (< 15 km) earthquakes from before to after Morakot. For this, we use a sliding window in space with a radius of 30 km, which allows us to detect large-scale features not affected by small sub-samples of events (see “Methods” section). It is applied separately to earthquakes in the 2.5 years before and after Morakot, respectively. Consistent with the temporal evolution of earthquake frequency, results show an increase in the number N of earthquakes after the typhoon over the landsliding zone (Fig. 4, Supplementary Fig. S8). This increase is observed for earthquakes with magnitudes above the completeness magnitude and also for all recorded earthquakes. It is not limited to the vicinity of the landsliding zone, but it also occurred in northeast Taiwan. However, outside the landsliding zone, increases in the b-value appear not to be associated to increases in the number of earthquakes. For instance, North-East Taiwan displays a significant increase in the number of earthquakes associated to a decrease of the b-value. We note that the spatial correlation between earthquake statistics change and the landsliding zone is less well resolved and less robust (see “Methods” section) than the temporal correlation.

Figure 4
figure4
Changes in seismicity after typhoon Morakot. (a) Map of difference of shallow (< 15 km) earthquake numbers, ΔN, during the 2.5 years after and before typhoon Morakot. Only earthquakes greater than the completeness magnitude were considered. For readability, ΔN values lower than 101.5 are shown in white. Red and blue circles locate earthquakes greater than magnitude 5 after and before typhoon Morakot, respectively. (b) Change in b-value, Δb (red-blue colormap), and uncertainty, σ (gray circles) of b-value estimates (see “Methods” section, Supplementary Fig. S3). Maps were performed using Matlab R2019b.

Full size image
Discussion
Previous intense erosional events associated with the Chi-Chi earthquake (1999), and typhoons Herb (1996) and Toraji (2001) did not induce any detectable change of seismicity. This may be because these events had less erosion, the total volume of ~ 0.45 km3 of landslides triggered by Chi-Chi earthquake25 being by far the largest, and because most landslides triggered by these events deposited debris distant from rivers14. Besides, the high rate of aftershocks after Chi-Chi prevents detection of a change in earthquake frequency or b-value associated with erosion due to Chi-Chi or Toraji, if there was any. We also note that the changes in earthquake frequency and b-value are not perfectly synchronous with typhoon Morakot and occur about 1–2 months after the typhoon. However, the time resolution of our temporal analysis does not allow us to detect with confidence changes occurring with a period less than about 100 days (see Supplementary Fig. S5b). The duration of the transient increase in earthquake frequency and b-value occurring after typhoon Morakot lasts about 2.5 years.

Non-erosional causes of the observed changes in earthquake statistics in SW Taiwan are possible but appear less likely. Earthquakes result from the stresses induced by tectonics, in general, but also by other earthquakes26. The 4th of March 2010, the Mw 6.3 Jiashian earthquake occurred within the landsliding zone, close to its western limit, and was followed by many aftershocks. However, this earthquake and most aftershocks are located at 15–25 km depth (Supplementary Fig. S11), as shown by seismological records27 and further confirmed by the declustering process, which mostly removes events below 15 km depth, (Fig. 3, Supplementary Fig. S10). Therefore, the Jiashian earthquake does not affect shallow earthquake statistics and cannot be considered responsible for the increase of the b-value after Morakot (Supplementary Fig. S10).

Hydrological triggering of seismicity after the heavy rainfall during typhoon Morakot, either by surface loading or by pore pressure diffusion28, could be an alternative mechanism. Indeed, on the east coast of Taiwan, where landslide erosion was limited, borehole water levels rose by 4 m after typhoon Morakot, and a volumetric contractional strain was observed29,30. However, both signals decayed in ~ 6 months and their amplitudes and temporal evolutions do not depart from the mean seasonal trends observed from 2006 to 2011. Moreover, pore pressure diffusion along permeable faults after large rainfall events generally leads to episodic increases of seismicity31 and not to prolonged changes as observed in our case.

The temporal and spatial collocation of intense landsliding triggered by typhoon Morakot and the observed increase of shallow earthquake frequency and b-value suggest a potential mechanistic link. Direct physical modeling of the impact of erosion during and after Morakot on seismicity is beyond our reach because the location, magnitude and rate of sediment export from the landsliding zone are not reliably constrained. Despite this, simple elastic models show that large erosional events with rapid sediment export can induce static stresses at depth, sufficient to modulate tectonic stresses on the shallower (< 5–10 km) parts of faults10. Removing 20 to 50% of the landslide volume in 2.5 years, equivalent to about 2 to 5 cm of average erosion over the landsliding zone, would lead to a Coulomb stress increment on a nearby thrust fault of about 0.1 10–1 to 0.25 10–1 bar at 5 km depth10, using a thrust dip angle of 30° and an effective friction of 0.6. These stress increments are roughly similar to the ones induced by seasonal hydrologic loading in the Himalaya, ~ 0.2–0.4 × 10–1 bar, which are suggested to lead to a seasonal modulation of earthquake frequency32.

In addition, spring-slider models33 and 2D elasto-dynamic models of seismogenic faults34 with rate-and-state friction laws35,36 show that the rate of seismicity can increase linearly or more than linearly due to a positive, step-like stress perturbation. It is also observed that shallow earthquakes generally have smaller magnitudes and larger b-values than deeper earthquakes37 possibly because they nucleate at lower differential stresses38. Our observations suggest that the intense and prolonged sediment export and surface unloading after typhoon Morakot could have acted as a progressive increase of stresses, with a complex spatio-temporal evolution, on the shallow parts of underlying thrust faults10, giving rise to a similar increase of shallow earthquake frequency and b-value in Southwest Taiwan.

The proposed erosional-driven mechanism to explain the changes in seismicity after Morakot offers new perspectives on the links between climate, erosion and tectonics4,5 at the time scale of elementary processes. While numerous studies have shown that earthquakes and storms can trigger landslides2,14,20,25, this is to our knowledge the first potential evidence of the short-term and ongoing influence of erosion on seismicity. Because the mechanical link between erosion and stresses is through crustal elasticity10, crustal deformation is sensitive not only to extreme weather-driven erosion but also to the cumulative effects of smaller but numerous erosion events. More frequent extreme rainfall, for instance under a warmer climate39, could result in accelerated sediment transport19 and in turn in changes in the rate of shallow earthquakes, similar to the modulation of seismicity by surface water load variations13. Over the duration of the transient increase in seismicity, the shallow but small-magnitude seismicity induced by erosion is not likely to trigger new landslides, and the seismic moment rate would not be significantly affected. Hence, we do not expect a significant feedback of this additional deformation on erosion. However, the impact of this short-term transient signal on the seismicity and erosion over longer time scales, such as the duration of a seismic cycle, remains to be investigated. Our results therefore call for a new generation of process-based models coupling landscape dynamics21 and fault dynamics34 at scales relevant to natural hazards and societal issues. In these models, storms, floods, mass wasting, river sediment transport, redistribution of water, elastic stress transfer, seismicity and seismic wave propagation should all be represented to account for the complexity of the links between climate, erosion and tectonics.

Methods
Morakot rainfall data
The map of cumulative rainfall during Morakot was obtained by natural-neighbor interpolation of cumulative hourly rain gauge measurements over the period 7 to 9th of August 2009. Data from 377 stations across Taiwan were used from the Data Bank for Atmospheric Research at the Taiwan Typhoon and Floods Research Institute.

Morakot landslide catalogue
Mapped landslides were delineated manually by comparing surface reflectivity and morphology on pre- and post-event FORMOSAT-2 satellite images40 (2 m panchromatic and 8 m multi-spectral). To cover most of the islands we mosaicked multiple cloud-free pre-event (01/14, 05/08, 05/09, 05/10, 06/06) and post-event (08/17, 08/19, 08/21, 08/28, 08/30, 09/06) images taken in 2009. For parts of the inventory, especially east of the main divide, landslides were first mapped automatically and then edited manually. For both approaches, the scar, runout and deposit areas are not differentiated. We did not consider debris flow transport areas and excluded gentle slopes (< 20°) from mapping to avoid confusion with human activity. Special attention was given to the separation of individual landslides, which had common transport or deposit areas but independent initiation points41. The robust and conservative estimation of landslide surface area is especially important for the estimation of landslide volume42.

Estimation of landslide volume
The landslide volume was estimated based on landslide area, following the method of ref. 16 and 41. Briefly, we assumed constant size ratios between scar and deposit areas of 1.1 and 1.9 for mixed and bedrock landslides, respectively42. Then, we converted the scar area into volume using a power law with different prefactor (α) and exponent (γ) for mixed and bedrock landslides, with α=0.146 and γ=1.332 for Ascar<1e5 m2 and α=0.234 and γ=1.41 for Ascar>1e5 m2, respectively41. Recent studies have proposed a regional scaling relationship for southern Taiwan, based on measurement of large landslides caused by typhoon Morakot43. With these parameters (α=0.202, γ=1.268), and without scar correction, we obtain volumes ~ 3 times larger for intermediate size (mixed) landslides and twice smaller volume for very large (bedrock) landslides. Overall, this would not change the order of magnitude of erosion nor the results discussed in this study. Distributing uniformly the total volume, ~ 1.2 km3, of landslides triggered by typhoon Morakot over the area of the landsliding zone, ~ 7,000 km2 , gives about 17 cm of thickness of mobilized sediments.

Estimation of sediment export after typhoon Morakot
There is currently no method allowing a robust and accurate measurement of sediment transport after typhoon Morakot, including suspended and bed loads, at the scale of Taiwan. Concerning suspended load, about 0.75 GT of sediments have been exported away in 2009 from the Gaoping catchment compared to an average ~ 0.02 GT/year over the period 1950–2008 (ref.19). Most of the 0.75 GT of sediment export in 2009 from the Gaoping catchment, which drains a large area of the west part of the landsliding zone, can therefore be attributed to the impact of the landslides triggered by Morakot. Similarly, over the Island of Taiwan, suspended sediment discharge increased from about a mean of ~ 0.38 GT/year to ~ 1.1 GT/year in 2009, and a large part of this increase can be attributed to the impact of Morakot19. In 2010, suspended sediment discharge decreases to pre-Morakot values, partly due to the absence of large water discharge events. Timescales for bedload sediment export is probably much larger, between a few years to decades21 and potentially centuries. Most rivers connected to the landsliding zone experienced rapid and intense sediment aggradation, with 10–100 m of sediment thickness, in response to Morakot typhoon. To our knowledge, no study has been published on the regional evolution of this bedload sediment mass. The estimated total volume 1.2 km3 of landslides triggered by Morakot could translate in about 2.5–3 GT of sediments. It is therefore likely that about 20–30% of this mass was removed by suspended transport in 2009, and probably a few percent or more in the following years. Therefore, a rough estimate could lead to possibly 20–40% of sediment export over the time period 2009–2012. Adding bedload transport could hypothetically increases this estimate to 20–50% for the time period 2009–2012.

Earthquake catalogue of Taiwan
We extracted earthquakes at shallow depths (< 15 km) from the earthquake catalogue of the Taiwan Central Weather Bureau44 for the period 1995–2015 over the emergent part of Taiwan. This catalogue is accessible through the Taiwan Central Weather Bureau (https://gdms.cwb.gov.tw). The monitoring network includes short-period and broadband seismographic systems stations. The location and number of seismic stations changed during the period 1995–2015. The configuration of the seismic network in the south of Taiwan and in the landsliding zone remained relatively similar over the period January 2007 to December 2012 (see Supplementary Fig. S8), but after 2012, 2.5 years after Morakot, the number of stations was increased mostly in North Taiwan. This has caused a decrease of the measured completeness magnitude over all of Taiwan, including in the landsliding zone (see Supplementary Fig. S2). We therefore do not focus our analysis on changes in the frequency of earthquakes occurring after 2.5 years after Morakot (beginning of 2012). Yet, we note that using a constant and conservative value for the completeness magnitude of 2.4 (see Fig. 2, Supplementary Fig. S3), we observed that earthquake frequency decreases to pre-Morakot values after about 2.5 years.

Characterization of earthquake size distribution
The Gutenberg–Richter distribution is classically used to characterize the relation of the number of earthquakes above a given magnitude, n(≥M)=10a−bM, to the magnitude M, where a and b are parameters related to the number of earthquakes and to the slope of the relationship, respectively. This relationship is appropriate only for magnitudes above the completeness magnitude, Mc, of the catalogue. Mc is determined by a modified version of the simple but robust maximum curvature method45, where Mc is equal to the maximum of the first derivative of the frequency-magnitude curve, plus 0.5. We compute a maximum likelihood estimate46 of the b-value, b=log10e/(M¯¯¯¯¯−Mc) and of its uncertainty, σ=b/√n(≥Mc), where M¯¯¯¯¯ is the mean magnitude of the considered earthquakes with M≥Mc. Note that the number of earthquakes considered has a strong control on the b-value estimate and its uncertainty47, and that only relative spatial or temporal changes of the b-value should be interpreted.

Time evolution of earthquake statistical properties
We use a temporal sliding window to subsample the earthquake catalogue and to assess time variations of earthquake statistical properties. Because the uncertainty of the b-value strongly depends on the number of considered events, and because larger samples give better estimates, we use a sliding window of N= 1,001 events to prevent undue statistical bias. The window is centred on a given earthquake and the corresponding b-value and earthquake frequency are determined for the 500 earthquakes that occurred immediately before and immediately after this event. Earthquake frequency is computed by dividing N by the temporal length of the sliding window. Among the 1,001 earthquakes, only those with magnitude above Mc are used to estimate the b-value. We assess the effect of changing the sampling method of the temporal window, by considering an a priori value of Mc=2.25, and considering a fixed number of earthquakes with a magnitude >Mc ranging from N= 101 to N= 1,001 (Supplementary Figs. S5, S6). We find a consistent increase of b-value in the 2.5 years after Morakot for N ranging from 101 to 501, as all these earthquakes occurred within a time window duration lower than 2.5 years. For N=751 or N= 1,001 the window duration is equal to or greater than 2.5 years (about 3 years for N= 1,001), which leads to over-smoothing of the signal, and prevents detection of changes occurring on shorter time-scales. It is also notable that changing the fitting method from maximum likelihood to least-square, which is generally considered less reliable, does not significantly change the relative variation of the b-value in time (Supplementary Fig. S5). This includes the changes occurring after Morakot.

Probability of earthquake frequency change with time
Following ref.48, we compute the probability P that the earthquake frequency increases by a factor greater than r between a period 1 and 2,

P(λ2λ1>r)=1−1N2!N1!∫∞0e−xΓ(N2+1,rxΔt2Δt1)xN1dx
where Γ(n,x)=∫∞0e−ttn−1dt is the incomplete Gamma function, N is the number of earthquake over a certain period Δt and λ=N/Δt is the earthquake frequency. The subscripts 1 and 2 refer to the time periods 1 and 2. We first apply this approach to determine the probability of earthquake frequency change between the 2.5 year before and after Morakot, in the landsliding zone considering only earthquakes with a depth shallower than 15 km (Supplementary Fig. S4a). We find a probability 1 for an increase of earthquake frequency (i.e. with r>1), when considering all the earthquakes or only earthquakes above the completeness magnitude. The 90% confidence interval, 0.05<P<0.95, of an earthquake frequency change is found for 1.23<r<1.40, when considering only the earthquakes above the completeness magnitude, and 1.45<r<1.52 for all magnitudes. This demonstrates that the change of earthquake frequency after Morakot is significant with a ratio of 1.23, at least. We then apply the same analysis to the entire catalog by using a double sliding window of period 2.5 years after and before the center time (Supplementary Fig. S4b). The largest increase in earthquake frequency, with a factor close to 5 for a probability inside the confidence interval, is Chi-chi earthquake. Except for Chi-Chi, the time period including typhoon Morakot and Jiashian earthquakeis the only one associated with a significant and positive change of earthquake frequency over a period of 2.5 years since 1994. However, as demonstrated in this manuscript, Jiashian earthquake did not lead to a significant increase in the number of earthquakes at shallow depths (Fig. 3; Supplementary Figs. S9, S10, S11, S13).

Spatial variations of earthquake statistical properties
We use a common spatial sliding window to subsample the earthquake catalogue and to assess variations of earthquake statistical properties in space49 between the 2.5 years before and after typhoon Morakot. We use a radius of 30 km for the sliding window, which enables sampling of a sufficiently large number of earthquakes at a length scale that is smaller than that of the landslide zone of 7,000 km2. The sampling window effectively corresponds to a disk shape extending to a depth of 15 km. The b-value is determined for the recorded earthquakes in each disk volume by maximum likelihood estimation. This method has an inherent statistical bias as the number of sampled earthquakes changes significantly depending on the local rate of seismicity. The minimum number of events for the determination of the b-value is set arbitrarily at 50. Our method can give rise to small-scale shapes in the maps of b-value, such as disk and rod shapes, that are not the focus of this study. We use a disk shape kernel with a radius of 15 km, convolved with the initial b-value map to blur the mapped patterns and to isolate features with longer wavelengths. More sophisticated methods exist to compute spatial variations of b-value, including a penalized likelihood-based method50 and a distance-dependent sampling algorithm51.

Declustering and seismicity changes after Morakot
Several studies investigating potential earthquake frequency changes use declustered earthquake catalogs. However, declustering is an ill-posed problem that does not have a unique solution52 and that will lead to method-dependent results. Yet, to test the impact of potential earthquake clustering on our results, we have applied the traditional Reasenberg declustering algorithm53, obtained from the ZMAP toolbox54, to the CWB earthquake catalog. This deterministic algorithm aims to remove earthquake sequences, defined as chains of connected earthquakes in space and time, leaving only the initial earthquake in a given sequence. We use standard parameters52 adapted for Taiwan with τmin=1 day the minimum look-ahead time for for building clusters when the first event is not clustered, τmax=10 days, the maximum look-ahead time for building clusters, pclust=0.95, a confidence probability, xmeff=2.0, the effective lower cutoff magnitude chosen here to be consistent with the CWB catalog, xk=0.5, the increase in lower cutoff magnitude during clusters, and rfact=10, the number of crack radii surrounding each earthquake within new events considered to be part of the cluster. We emphasize here that declustering has been performed over the entire catalog, without any regional selection of the seismicity (i.e. not only in the landsliding zone and not only above 15 km of depth), to prevent potential declustering biases associated to earthquake censoring.

Supplementary Figure S9 shows the influence of declustering on earthquake frequency, b-value, depth distribution and the probability of earthquake frequency change after Morakot in the landsliding zone (< 15 km depth). We observe that declustering mainly leads to a decrease of earthquake frequency over the 2.5 years before typhoon Morakot, and to very minor changes after. We find that declustering even slightly enhances the probability of an increase in earthquake frequency after Morakot. In addition, declustering does not significantly changes the time variation in b-value nor the depth-distribution of seismicity. We note that the Reasenberg declustering approach is well-suited to remove earthquake sequences that lead to significant changes (e.g. an aftershock sequence after a large mainshock) and not to identify potential triggered events during quiet periods associated with a constant and low frequency of earthquakes48. Under this potential limitation, this analysis demonstrates that earthquake clustering is not the reason for the observed changes after typhoon Morakot.

In addition, we are confident that large and deep mainshocks occurring in the landsliding zone, below 15 km, such as Mw 6.3 Jiashian earthquake in 2010, are not the cause for the observed seismicity changes. Indeed, declustering is efficient to remove most of the aftershocks caused by the Jiashian earthquake, which appear to be concentrated at depth between 15 and 30 km (Supplementary Fig. S10). To confirm this inference, we vary the values of the declustering parameters using a range of acceptable values around the reference values48,55: τmin=0.5−2.5 days, τmax=3−15 days, pclust=0.90−0.99, xk=0−1 and rfact=5−20. We use a random sampling of the parameters space within these ranges, using a Monte-Carlo approach, to define 50 declustering parameter combinations. We obtain similar results, in terms of earthquake depth-distribution (Supplementary Fig. S9) and temporal variations of earthquake frequency (Supplementary Fig. S10) as in the reference declustering model. This confirms the robustness of the observed changes in shallow seismicity after Morakot that are not related to earthquake interactions.

Seismicity temporal variation: random hypothesis versus significant regional seismicity change versus local earthquake interactions
Having a declustered catalog should theoretically imply that all the earthquakes are seismically independent from each other. In turn, earthquakes should be randomly distributed in time, unless a non-seismic process triggers them. Here we test this hypothesis by comparing the observed changes, in earthquake frequency and b-value after Morakot, obtained from the “true” declustered catalog with those from 200 “synthetic” earthquake catalogs over the period 2006–2015. Each synthetic catalog is generated using the exact same earthquakes as in the true declustered catalog, including their magnitudes, but the time of occurrence of each earthquake is randomly sampled over the period of interest (2006–2015) using a time step of 1 s. It results that each synthetic catalog has the exact same magnitude distribution and average earthquake frequency than the true one, but the temporal distribution of earthquakes is randomly distributed. For each catalog (true or synthetic), the probability of frequency change and the change in b-value after Morakot are computed by comparing the earthquakes occurring in the 2.5 years after and before Morakot (see Supplementary Fig. S12). The probability of a frequency change after Morakot for all the synthetic catalogs drops around a ratio 0.8–1.2, centered around 1, meaning there is no significant frequency change. This clearly departs from the frequency change observed using the true catalog that drops around a ratio of 1.3–1.6. In addition, the change in b-value of the true catalog is significantly greater than the changes of all the synthetic catalogs. Overall, these results mean that both the frequency change and the b-value increase after Morakot are robust features, that depart from random changes. In addition, because we performed these tests using the declustered catalog, which should only include independent earthquakes, this means that these robust and non-random changes should not be associated to the occurrence of large mainshocks. We also note that potential earthquake interactions in a local subset of the landsliding zone56 cannot explain the increase in earthquake frequency after Morakot (Supplementary Fig. S13).

Data availability
The datasets used in this study are provided along with the manuscript. The earthquake catalogue is also accessible through the Taiwan Central Weather Bureau (https://gdms.cwb.gov.tw). The rainfall data is also accessible through Data Bank for Atmospheric Research at the Taiwan Typhoon and Floods Research Institute (https://www.narlabs.org.tw/en). The landslide dataset is also available by request to O.M., P.M. and N.H.